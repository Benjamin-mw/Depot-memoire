---
title: "GLM"
author: "Dudot Lucas - Lapaz Eudes - Moinard Benjamin - Nanoux Louis"
date: "2023-01-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = TRUE, message = FALSE, error = FALSE}
library(FactoMineR)
library(factoextra)
library(CASdatasets)
library(tidyverse)
library(MASS)
library(knitr)
library(ggplot2)
library(cowplot)
library(reshape2)
library(dplyr)
library(GGally)
library(corrplot)
library(carData) 
library(car)
library(questionr)
library(multcomp)
library(dplyr)
library(leaps)
library(TeachingDemos)
library(factoextra)
library(ROCR)
library(plotROC)
library(caret)
```

# GLM pour la variable coût

## I) Transformation de certaines variables en variables catégorielles

```{r}
data(freMPL5)
```

Notre variable "ClaimAmount" est une variable quantitative et représente le prix total des accidents survenus au cours de l'année pour chacun des assurés.

Cette variable prend ainsi une valeur nulle lorque la variable "ClaimInd" a la valeur nulle, c'est-à-dire si aucun accident n'est survenu et prend des valeurs positives dans le cas contraire.

```{r}
summary(freMPL5$ClaimAmount)
```

Seulement, nos données présentent des cas particuliés et isolés dans laquelle la variable ClaimAmount prend des valeurs négatives. Nous élimineront ces données dans la suite de notre étude de la variable et nous nous intéresserons aux valeurs que celle-ci peut prendre lorsqu'un incident a lieu.

Nous utiliserons également le même découpage réalisé lors de l'étude de la variable fréquence.

```{r}
#enlever les valeurs négatives
freMPL5 <- subset(freMPL5, freMPL5$ClaimAmount >= 0)

#passer en variables catégorielles
freMPL5$HasKmLimit <- factor(freMPL5$HasKmLimit)
freMPL5$ClaimInd <- factor(freMPL5$ClaimInd)

#segmentation des tranches d'âge
freMPL5$DrivAge_fact <- cut(freMPL5$DrivAge, c(20,25,30,35,40,45,50,58,65,120), include.lowest = TRUE)

#Découpage CSP
freMPL5$Categ <-  ifelse(freMPL5$SocioCateg %in% c("CSP46","CSP48"), "Categ1",
ifelse(freMPL5$SocioCateg %in% c("CSP50","CSP55"), "Categ2",
ifelse(freMPL5$SocioCateg %in% c("CSP60"),"Categ3",
ifelse(freMPL5$SocioCateg %in% c("CSP42","CSP1", "CSP66"),"Categ4","Categ0"))))
freMPL5$Categ = factor(freMPL5$Categ)

#découpage RiskArea
freMPL5$RiskArea <- ifelse(freMPL5$RiskArea %in% c(1,2,3,12,13), "ZoneRisque1",
ifelse(freMPL5$RiskArea %in% c(5,6,7,8,9), "ZoneRisque2",
ifelse(freMPL5$RiskArea %in% c(10,11), "ZoneRisque3",
ifelse(freMPL5$RiskArea %in% c(4), "ZoneRisque4", NA))))

freMPL5$RiskArea <- factor(freMPL5$RiskArea)
```

```{r}
summary(freMPL5$Categ)

```

Le coefficient de bonus-malus est réglementaire, ne faut-il pas le rajouter que plus tard dans la tarification ?

Nous allons faire un système à double pénalisation, "BonusMalus" sera pris en compte dans nos GLMs et notre grille de tarification.

## II) Première estimation de la loi de notre variable "ClaimAmount"

```{r, error = TRUE}
cout <- freMPL5[freMPL5$ClaimInd == 1,]
```

```{r}
summary(cout$ClaimAmount)
```

Dans un premier temps , on observe une répartition très inégale des montants des accidents. En plus d'une moyenne de 2277.22 et d'une médiane à 800.95, le montant maximal des accidents de notre jeu de données est de 95150.96.

```{r}
hist(cout$ClaimAmount)
plot(cout$ClaimAmount)
abline (a=60000,b=0, col ="red")
#on observe dans un premier temps deux valeurs extremes qui dépassent de 47 fois la moyenne.

#Etudions toujours la répartition de la variable de sévérité privé de ces deux valeurs extrêmes.
cout1 <- subset(cout, cout$ClaimAmount <60000)
hist(cout1$ClaimAmount)
plot(cout1$ClaimAmount)
abline (a=35000,b=0, col ="blue")
#Pour une étude non biaisée vers d'autres valeurs moins extrêmes, il serait également préferable de faire une étude sur des montants inférieurs à 35000€. Seulement sept observations ont été estimées supérieures à ce prix.

cout2 <- subset(cout, cout$ClaimAmount <35000)
hist(cout2$ClaimAmount)
plot(cout2$ClaimAmount)
```

### a) Estimation d'une loi

Dans notre étude sur la variable de sévérité ClaimAmount, nous allons essayer d'approcher la distribution de cette variable par une loi continue connue.

Nous utiliserons la méthode du qqplot

```{r}
#Approche par une loi Gamma
alpha = mean(cout$ClaimAmount)^2/var(cout$ClaimAmount)
beta = mean(cout$ClaimAmount)/var(cout$ClaimAmount)
qqplot (cout$ClaimAmount, qgamma ( ppoints (cout$ClaimAmount,3/8), shape =alpha, rate =beta),
        	xlab ="Prix des sinistres observés",
        main ="Graphique des quantiles pour les prix des sinistres (loi gamma).")
abline (a=0,b=1, col ="red")
```

La loi gamma semble très bien s'adapter à notre modèle. De plus, une divergence avec la loi est observée lorsque les valeurs sont supérieures à 35 000. Cela nous maintient dans l'idée d'étudier notre jeu de données aux montants inférieurs à 35000.

```{r}
qqplot (cout$ClaimAmount, qnorm ( ppoints (cout$ClaimAmount,3/8), mean =mean(cout$ClaimAmount), sd =sqrt(var(cout$ClaimAmount))),
        	xlab ="Prix des sinistres observés",
        main ="Graphique des quantiles pour les prix des sinistres (loi normale).")
abline (a=0,b=1, col ="red")
```

La loi normale ne semble pas être très adaptée à notre modèle

```{r}
#Approche par la loi log normale
fit_params <- fitdistr(cout2$ClaimAmount,"lognormal")
qqplot (cout2$ClaimAmount, qlnorm ( ppoints (cout2$ClaimAmount,3/8), mean = fit_params$estimate['meanlog'], sd = fit_params$estimate['sdlog']),
        	xlab ="Prix des sinistres observés",
        main ="Graphique des quantiles pour les prix des sinistres (loi log normale).")
abline (a=0,b=1, col ="red")
```

### b)Séparation en échantillon apprentissage et échantillon test

```{r}
cout3 <- subset(cout, cout$ClaimAmount <20000)
set.seed(123)
perm <- sample(nrow(cout3),80/100*nrow(cout3))
train <- cout3[perm,]
test <- cout3[-perm,]
```

## III) Etude des outliers

Cette partie sera consacrée à l'étude d'outliers. Cette dernière peut s'avérer utile pour avoir un modèle le plus efficient possible. Nous avons commencé à enlever des valeurs extrêmes en limitant le domaine d'étude aux sinistres de montant inférieur à 20000€. Affinons cette recherche grâce à d'autres méthodes mises à notre disposition.

### a) Méthode d'Hampel

```{r}
q= 3 
# calcule la borne inf de l'intervalle binf
borne_inf <- median(train$ClaimAmount) - q * mad (train$ClaimAmount) 
#mad représente la déviation absolue de la médiane
borne_inf 

# calcule la borne sup de l'intervalle bsup 
borne_sup <- median(train$ClaimAmount) + q * mad (train$ClaimAmount) 
borne_sup

#On renvoie les indices des outliers potentiels

indices_outliers <- which(train$ClaimAmount < borne_inf | train$ClaimAmount > borne_sup)
indices_outliers
length(indices_outliers)

#On renvoie les valeurs prises par nos outliers

valeurs_outliers <- train[indices_outliers,"ClaimAmount"]
valeurs_outliers

#Puis on retire les outliers de notre échantillon

train_Hampel=slice(train,-indices_outliers)
```

### b) Méthode de Tukey combiné à la méthode d'Hampel

Faisons un plot pour voir si certains outliers peuvent encore apparaître avec la distance de Cook

```{r}
plot(gamma.id_Hampel <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel, family = Gamma(link = "identity")))

#On effectue un test de Bonferroni
outlierTest(gamma.id_Hampel)
```

Voyons voir ce que donne le GLM gamma avec ce nouvel échantillon

```{r}
gamma.inv_Hampel <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel, family = Gamma(link = "inverse"),start =rep(10e-10,28))
summary(gamma.inv_Hampel)
```

```{r}
gamma.log_Hampel <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+BonusMalus*Categ, data = train_Hampel, family = Gamma(link = "log"))
summary(gamma.log_Hampel)

gamma.id_Hampel <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel, family = Gamma(link = "identity"))
summary(gamma.id_Hampel)
```

#### b) Méthode de Tukey combiné à la méthode d'Hampel

Cette méthode se base sur l'écart interquartile et permet de détecter de potentiels outliers

```{r}
# Calculer l'écart interquartile (IQR)
iqr <- IQR(train_Hampel$ClaimAmount)

# Calculer les bornes de la méthode de Tukey
lower_bound <- quantile(train_Hampel$ClaimAmount, 0.25) - 1.5*iqr
upper_bound <- quantile(train_Hampel$ClaimAmount, 0.75) + 1.5*iqr

# Identifier les outliers
outliers_tukey_valeurs <- train_Hampel$ClaimAmount[train_Hampel$ClaimAmount < lower_bound | train_Hampel$ClaimAmount > upper_bound]

#On extrait les indices de ces outliers
outliers_tukey_indices <- which(train_Hampel$ClaimAmount < lower_bound | train_Hampel$ClaimAmount > upper_bound)

# Afficher les résultats
outliers_tukey_valeurs
length(outliers_tukey_valeurs)
outliers_tukey_indices

#On enlèves ces outliers de notre échantillon 

train_Hampel_Tukey=slice(train_Hampel,-outliers_tukey_indices)
```

### c) Méthode de Tukey

```{r}
# Calculer l'écart interquartile (IQR)
iqr_1 <- IQR(train$ClaimAmount)

# Calculer les bornes de la méthode de Tukey
lower_bound_1 <- quantile(train$ClaimAmount, 0.25) - 1.5*iqr_1
upper_bound_1 <- quantile(train$ClaimAmount, 0.75) + 1.5*iqr_1

# Identifier les outliers
outliers_tukey_valeurs_1 <- train$ClaimAmount[train$ClaimAmount < lower_bound_1 | train$ClaimAmount > upper_bound_1]

#On extrait les indices de ces outliers
outliers_tukey_indices_1 <- which(train$ClaimAmount < lower_bound_1 | train$ClaimAmount > upper_bound_1)

# Afficher les résultats
outliers_tukey_valeurs_1
length(outliers_tukey_valeurs_1)
outliers_tukey_indices_1

#On enlèves ces outliers de notre échantillon 

train_Tukey=slice(train,-outliers_tukey_indices_1)
```

Par la suite, nous nous servirons de ces méthodes dans nos glm pour affiner la qualité de prédiction de ces derniers.

### d) Existence d'éventuels autres outliers

Pour voir si d'autres outliers, nous nous servirons de la fonction "outliersTest". La méthode OutliersTest consiste à calculer la distance de chaque valeur de l'ensemble de données à la moyenne ou à la médiane de l'ensemble de données. Si cette dernière est plus élevée qu'un seuil prédéfini, la valeur sera considérée comme aberrante.

```{r}
outlierTest(gamma.id_Hampel)
```

## IV) Loi gamma

Nous allons faire un GLM avec la loi gamma et les liens identité, inverse et log.

### A) Lien inverse

#### 1) Echantillon sans étude d'outliers / sans intéraction

```{r}
gamma.inv_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = Gamma(link = "inverse"),start =rep(10e-10,28))
summary(gamma.inv_0)
```

La commande "start =rep(0.01,28)" permet de donner une valeur inititale aux coefficients que l'on cherche à estimer. Sans cette commande, le code renvoie un message d'erreur

Nous verrons par la suite que nos modèles appliqués aux données issues de la méthode d'Hampel et du Tukey nous permettent de palier ce problème.

#### 2) Echantillon sans étude d'outliers / avec intéractions

Après avoir testé de nombreuses interactions entre les variables, l'interaction "ClaimNbNonResp\*ClaimNbResp" est celle qui a davantage d'impact sur le modèle et permet l'apparition d'un paramètre de p valeur inférieur à 0.05

```{r}
gamma.inv_1 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+ClaimNbNonResp*ClaimNbResp,data = train, family = Gamma(link = "inverse"),start =rep(10e-10,29))
summary(gamma.inv_1)
```

Ce message d'erreur indique que l'algorithme n'a pas convergé. Nous verrons par la suite que les intéractions sont plus significatives pour d'autres liens et d'autres données.

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod0_gamma_inv_0 <- glm(ClaimAmount ~ 1, data = train, family = Gamma(link = "inverse"))
AIC(mod0_gamma_inv_0)
```

```{r}
modBoth_gamma_inv_1 = step(gamma.inv_1, mod0_gamma_inv_0, trace=F,direction = c('both'), start=rep(10e-10,29))
summary(modBoth_gamma_inv_1)
```

Nous ne nous éterniserons pas davantage sur ce message d'erreur. En effet, cela marchera davantage avec d'autres données

#### 4) Echantillon avec études d'outliers et intéractions : Hampel

```{r}
gamma.inv_Hampel_0<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+ClaimNbNonResp*ClaimNbResp,data = train_Hampel, family = Gamma(link = "inverse"))
summary(gamma.inv_Hampel_0)
```

Nous voyons que nous n'avons plus besoin de fournir un jeu de données de départ.

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod0_gamma_inv_Hampel <- glm(ClaimAmount ~ 1, data = train_Hampel, family = Gamma(link = "inverse"))
AIC(mod0_gamma_inv_Hampel)
```

```{r}
modBoth_gamma_inv_Hampel = step(gamma.inv_Hampel_0, mod0_gamma_inv_Hampel, trace=F,direction = c('both'))
summary(modBoth_gamma_inv_Hampel)
```

L'écart d'AIC entre les modèle réduit à l'intercept et both n'est pas conséquent.

#### 5) Echantillon avec études d'outliers et intéractions : Tukey

```{r}
gamma.inv_Tukey<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+ClaimNbNonResp*ClaimNbResp,data = train_Tukey, family = Gamma(link = "inverse"))
summary(gamma.inv_Tukey)
```

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod0_gamma_inv_Tukey <- glm(ClaimAmount ~ 1, data = train_Tukey, family = Gamma(link = "inverse"))
AIC(mod0_gamma_inv_Tukey)
```

```{r}
modBoth_gamma_inv_Tukey = step(gamma.inv_Tukey, mod0_gamma_inv_Tukey, trace=F,direction = c('both'))
summary(modBoth_gamma_inv_Tukey)
```

### B) Lien log

#### 1) Echantillon sans étude d'outliers / sans intéraction

```{r}
gamma.log_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = Gamma(link = "log"))
summary(gamma.log_0)
```

#### 2) Echantillon sans étude d'outliers / avec intéraction

```{r}
gamma.log_1 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+RiskArea*MariStat,data = train, family = Gamma(link = "log"))
summary(gamma.log_1)
```

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod0_gamma_log_1 <- glm(ClaimAmount ~ 1, data = train, family = Gamma(link = "log"))
AIC(mod0_gamma_log_1)
```

```{r}
modBoth_gamma_log_1 = step(gamma.log_1, mod0_gamma_log_1, trace=F,direction = c('both'))
summary(modBoth_gamma_log_1)
```

L'apparition de nombreuses variables significatives à notre modèle (dont la p valeur est inférieure à 0.05), nous fait penser dans un premier temps que ce modèle est très adapté à notre jeu de données.

```{r}
# Regardons la différence d'AIC apporté par les variables
abs(AIC(modBoth_gamma_log_1)-AIC(mod0_gamma_log_1))
```

##### RMSE

```{r}
RMSE_train <- sqrt(mean(modBoth_gamma_log_1$residuals^2))
RMSE_train
```

#### 3) Echantillon avec étude d'outliers et intéractions : Tukey

```{r}
gamma.log_Tukey<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+RiskArea*MariStat,data = train_Tukey, family = Gamma(link = "log"))
summary(gamma.log_Tukey)
```

##### AIC

```{r}
mod0_gamma_log_Tukey <- glm(ClaimAmount ~ 1, data = train_Tukey, family = Gamma(link = "inverse"))
summary(mod0_gamma_log_Tukey)
```

```{r}
modBoth_gamma_log_Tukey = step(gamma.log_Tukey, mod0_gamma_log_Tukey, trace=F,direction = c('both'))
summary(modBoth_gamma_log_Tukey)

```

##### RMSE

```{r}
RMSE_train_Tukey_log <- sqrt(mean(modBoth_gamma_log_Tukey$residuals^2))
RMSE_train_Tukey_log
```

### B) Lien Identité

#### 1) Echantillon sans outliers / sans intéraction

```{r}
mod0_gamma_id_0 <- glm(ClaimAmount ~ 1, data = train, family = Gamma(link = "identity"))
AIC(mod0_gamma_id_0)
```

```{r}
gamma.id_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = Gamma(link = "identity"))
summary(gamma.id_0)
```

```{r}
# Vérification de la convergence du modèle plein
gamma.id_0$converged
```

Le modèle a divergé, il ne sera pas nécessaire d'effectuer la méthode Both dessus. Verifions s'il est possible de le faire converger en ajoutant des intéractions entre les variables.

#### 2) Echantillon sans outliers / avec intéractions

```{r}
gamma.id_1 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+RiskArea*ClaimNbWindscreen,data = train, family = Gamma(link = "identity"),start =rep(10e-10,31))
summary(gamma.id_1)
```

L'algorithme ne converge toujours pas. Nous allons maintenant nous intéresser à l'étude des outliers afin de résoudre ce problème de divergence

#### 3) Echantillon avec étude d'outliers et intéractions : Tukey

```{r}
gamma.id_Tukey<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+RiskArea*MariStat,data = train_Tukey, family = Gamma(link = "identity"),start =rep(10e-10,31))
summary(gamma.id_Tukey)
```

```{r}
mod0_gamma_id_Tukey <- glm(ClaimAmount ~ 1, data = train_Tukey, family = Gamma(link = "identity"))
AIC(mod0_gamma_id_Tukey)

modBoth_gamma_id_Tukey = step(gamma.log_Tukey, mod0_gamma_log_Tukey, trace=F,direction = c('both'))
summary(modBoth_gamma_id_Tukey)
```

## Prediction du meilleur modèle

### Both, forward and backward

```{r}
estimation <- gamma.log_Tukey$fitted.values
hist(estimation)
estimation <- gamma.log$fitted.values
hist(estimation)
```

```{r}
prediction <- predict.glm(gamma.log_Tukey, newdata = test, type = "response")
hist(prediction)
prediction <- predict.glm(gamma.log, newdata = test, type = "response")
hist(prediction)
```

## V) Loi Gaussienne Inverse

### A) Lien 1/mu\^2

#### 1) Echantillon sans outliers / sans interactions

```{r}
invgauss.mu_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "1/mu^2"),start=rep(10e-20,28))

```

Apparition d'un problème de divergence, voyons si le modèle vide est aussi divergeant

```{r}
mod_invgauss_mu_0 <- glm(ClaimAmount ~ 1, data = train, family = inverse.gaussian(link = "1/mu^2"))
AIC(mod_invgauss_mu_0)
```

#### 2) Echantillon sans outliers / avec interactions

Verifions s'il est possible de trouver des interactions de variables tel que le modèle converge.

```{r}
invgauss.mu_1<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea,data = train, family = Gamma(link = "1/mu^2"),start=rep(10e-20,52))

```

```{r}
#verification sur la convergence du modèle
invgauss.mu_1$converged
```

Le modèle ne converge toujours pas. Vérifions s'il est possible de le rendre convergeant à l'aide des méthodes d'outliers.

#### 3) Etude avec intéractions et outliers : Tukey

```{r}
invgauss.mu_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Tukey, family = inverse.gaussian(link = "1/mu^2"),start=rep(10e-20,28))

#"Est-ce que l'algorime converge ? "
invgauss.mu_Tukey$converged
```

### B) Lien Identité, inverse et log

#### 1) Echantillon sans outliers / sans interactions

```{r}
invgauss.id <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "identity"),na.action = na.exclude)
#(na.action = na.exclude) permet d'effectuer le GLM sans prendre compte des possibles données manquantes de notre échantillon train
```

```{r}
invgauss.inv <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "inverse"),na.action = na.exclude)
```

Ce message d'erreur apparait suite à la présence de données avec des valeurs Inf, manquantes, indéfinies ou non numériques mais aussi lorsque les variables ne sont pas appropriées pour la regression logistique de notre modèle. Or nous n'avons pas de valeurs manquantes exceptées pour la variable "RecordBeg" d'après le code suivant :

```{r}
dataSansRecordBeg <- train[, -4]
if (sum(is.na(dataSansRecordBeg)) > 0) {
  NaMiss <- 1
  #présence d'au moins une valeur manquante
} else {
  NaMiss <- 0
  #abscence de valeurs manquantes
}
print(NaMiss)
```

Voyons pour le lien "log"

```{r}
invgauss.log <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "log"))
```

Apparaît alors un message comme "Error: boucle interne 1 ; impossible de corriger le pas"

Essayons de voir s'il est possible d'obtenir des GLM à l'aide des méthodes des outliers.

#### 2)Echantillon avec outliers

```{r}
invgauss.id_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel_Tukey, family = inverse.gaussian(link = "identity"),na.action = na.exclude)

```

```{r}
invgauss.log_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel_Tukey, family = inverse.gaussian(link = "log"),na.action = na.exclude)

```

Le lien "identité" et "log" renvoient le même message d'erreur pour chaque méthode des outliers et ne sont pas appropriés pour une regression logistique de la loi inverse gaussienne.

```{r}
invgauss.inv_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Tukey, family = inverse.gaussian(link = "inverse"))
summary(invgauss.inv_Tukey)

```

#### a) Comparaison entre Modèle plein et vide

```{r}
mod0_invgauss_inv_Tukey_1 <- glm(ClaimAmount ~ 1, data = train_Tukey, family = inverse.gaussian(link = "inverse"))
AIC(mod0_invgauss_inv_Tukey_1)
```

```{r}
modBoth_invgauss_inv_Tukey_1 = step(invgauss.inv_Tukey, mod0_invgauss_inv_Tukey_1, trace=F,direction = c('both'))
summary(modBoth_invgauss_inv_Tukey_1)
```

## VI) Loi Log Normale

### A) Lien identité

#### 1) Echantillon sans outliers

```{r}
lognorm.id_0 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = gaussian(link = "identity"))
summary(lognorm.id_0)
```

Essayons de reduire l'AIC avec l'aide de nouvelles interactions

```{r}
lognorm.id_1 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+HasKmLimit*ClaimNbNonResp+ClaimNbNonResp*VehUsage, data = train, family = gaussian(link = "identity"))
summary(lognorm.id_1)
```

Comparons les avec le modèle réduit à l'intercept

```{r}
mod0_lognorm_id_0 <- glm(log(ClaimAmount) ~ 1, data = train, family = gaussian(link = "identity"))
AIC(mod0_lognorm_id_0)
```

Regardons le modèle réduit par la méthode Both

```{r}
modBoth_lognorm_id_1 = step(lognorm.id_1, mod0_lognorm_id_0, trace=F,direction = c('both'))
summary(modBoth_lognorm_id_1)
```

#### 2) Echantillon avec études des outliers

##### Méthode Tukey

```{r}
lognorm.id_Tukey <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+HasKmLimit*ClaimNbNonResp+ClaimNbNonResp*VehUsage, data = train_Tukey, family = gaussian(link = "identity"))

mod0_lognorm_id_Tukey_1 <- glm(log(ClaimAmount) ~ 1, data = train_Tukey, family = gaussian(link = "identity"))
modBoth_lognorm_id_Tukey_1 = step(lognorm.id_Tukey, mod0_lognorm_id_Tukey_1, trace=F,direction = c('both'))

summary(mod0_lognorm_id_Tukey_1)
summary(lognorm.id_Tukey)
summary(modBoth_lognorm_id_Tukey_1)
```

### B) Lien inverse

#### 1) Echantillon sans les outliers

Modele Complet :

```{r}
lognorm.inv_0 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = gaussian(link = "inverse"))

summary(lognorm.inv_0)
```

Modèle avec des interactions :

```{r}
lognorm.inv_1 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+HasKmLimit*ClaimNbNonResp+ClaimNbNonResp*VehUsage, data = train, family = gaussian(link = "inverse"))

summary(lognorm.inv_1)
```

Regardons l'AIC du modèle réduit à l'intercept

```{r}
mod0_lognorm_inv_0 <- glm(log(ClaimAmount) ~ 1, data = train, family = gaussian(link = "inverse"))
AIC(mod0_lognorm_inv_0)
```

```{r}
modBoth_lognorm_inv_1 = step(lognorm.inv_1, mod0_lognorm_inv_0, trace=F,direction = c('both'))
summary(modBoth_lognorm_id_1)
```

#### 2) Echantillon avec études des outliers

##### Méthode Tukey

```{r}
lognorm.inv_Tukey <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+HasKmLimit*ClaimNbNonResp+ClaimNbNonResp*VehUsage, data = train_Tukey, family = gaussian(link = "inverse"))

mod0_lognorm_inv_Tukey_1 <- glm(log(ClaimAmount) ~ 1, data = train_Tukey, family = gaussian(link = "inverse"))
modBoth_lognorm_inv_Tukey_1 = step(lognorm.inv_Tukey, mod0_lognorm_inv_Tukey_1, trace=F,direction = c('both'))

summary(mod0_lognorm_inv_Tukey_1)
summary(lognorm.inv_Tukey)
summary(modBoth_lognorm_inv_Tukey_1)
```

### C) Lien log

#### 1)Echantillon sans outliers

```{r}
lognorm.log_0 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = gaussian(link = "log"))

summary(lognorm.log_0)

```

```{r}
lognorm.log_1 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+ClaimNbNonResp*HasKmLimit+ClaimNbNonResp*VehUsage, data = train, family = gaussian(link = "log"))

summary(lognorm.log_1)
```

Modèle réduit à l'intercept :

```{r}
mod0_lognorm_log_0 <- glm(log(ClaimAmount) ~ 1, data = train, family = gaussian(link = "log"))
AIC(mod0_lognorm_log_0)
```

```{r}
modBoth_lognorm_log_1 = step(lognorm.log_1, mod0_lognorm_log_0, trace=F,direction = c('both'))
summary(modBoth_lognorm_log_1)
```

#### 2) Echantillon avec études des outliers

##### Méthode Tukey

```{r}
lognorm.log_Tukey <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+HasKmLimit*ClaimNbNonResp+ClaimNbNonResp*VehUsage, data = train_Tukey, family = gaussian(link = "log"))

mod0_lognorm_log_Tukey_1 <- glm(log(ClaimAmount) ~ 1, data = train_Tukey, family = gaussian(link = "log"))
modBoth_lognorm_log_Tukey_1 = step(lognorm.inv_Tukey, mod0_lognorm_log_Tukey_1, trace=F,direction = c('both'))


summary(lognorm.log_Tukey)
summary(mod0_lognorm_log_Tukey_1)
summary(modBoth_lognorm_log_Tukey_1)
```

# VII) Quelques critères

## Deviance

### Loi Gamma

Pour la fonction de lien "inverse" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_gamma_inv_Tukey))
  #modèle plein
round(deviance(gamma.inv_Tukey))
  #modèle both
round(deviance(modBoth_gamma_inv_Tukey))
```

Pour la fonction de lien "log" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_gamma_log_1))
  #modèle plein
round(deviance(gamma.log_1))
  #modèle both
round(deviance(modBoth_gamma_log_1))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_gamma_log_Tukey))
  #modèle plein
round(deviance(gamma.log_Tukey))
  #modèle both
round(deviance(modBoth_gamma_log_Tukey))
```

Pour la fonction de lien "identité" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_gamma_id_Tukey))
  #modèle plein
round(deviance(gamma.id_Tukey))
  #modèle both
round(deviance(modBoth_gamma_id_Tukey))
```

### Loi Inverse Gaussienne

Pour la fonction de lien "1/mu\^2" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
deviance(mod0_invgauss_mu_Tukey_1)
  #modèle plein
deviance(invgauss.mu_Tukey)
  #modèle both
deviance(modBoth_invgauss_mu_Tukey_1)
```

Pour la fonction de lien "inverse" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
deviance(mod0_invgauss_inv_Tukey_1)
  #modèle plein
deviance(invgauss.inv_Tukey)
  #modèle both
deviance(modBoth_invgauss_inv_Tukey_1)
```

### Loi Log Normale

Pour la fonction de lien "identité" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_lognorm_id_0))
  #modèle plein
round(deviance(lognorm.id_1))
  #modèle both
round(deviance(modBoth_lognorm_id_1))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_lognorm_id_Tukey_1))
  #modèle plein
round(deviance(lognorm.id_Tukey))
  #modèle both
round(deviance(modBoth_lognorm_id_Tukey_1))
```

Pour la fonction de lien "inverse" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_lognorm_inv_0))
  #modèle plein
round(deviance(lognorm.inv_1))
  #modèle both
round(deviance(modBoth_lognorm_inv_1))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_lognorm_inv_Tukey_1))
  #modèle plein
round(deviance(lognorm.inv_Tukey))
  #modèle both
round(deviance(modBoth_lognorm_inv_Tukey_1))
```

Pour la fonction de lien "log" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_lognorm_log_0))
  #modèle plein
round(deviance(lognorm.log_1))
  #modèle both
round(deviance(modBoth_lognorm_log_1))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(deviance(mod0_lognorm_log_Tukey_1))
  #modèle plein
round(deviance(lognorm.log_Tukey))
  #modèle both
round(deviance(modBoth_lognorm_log_Tukey_1))
```

## -2\*log(L)

### Loi Gamma

Pour la fonction de lien "inverse" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_gamma_inv_Tukey)))
  #modèle plein
round(-2*as.numeric(logLik(gamma.inv_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_gamma_inv_Tukey)))
```

Pour la fonction de lien "log" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_gamma_log_1)))
  #modèle plein
round(-2*as.numeric(logLik(gamma.log_1)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_gamma_log_1)))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_gamma_log_Tukey)))
  #modèle plein
round(-2*as.numeric(logLik(gamma.log_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_gamma_log_Tukey)))
```

Pour la fonction de lien "identité" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_gamma_id_Tukey)))
  #modèle plein
round(-2*as.numeric(logLik(gamma.id_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_gamma_id_Tukey)))
```

### Loi Inverse Gaussienne

Pour la fonction de lien "1/mu\^2" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_invgauss_mu_Tukey_1)))
  #modèle plein
round(-2*as.numeric(logLik(invgauss.mu_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_invgauss_mu_Tukey_1)))
```

Pour la fonction de lien "inverse" :

```{r}
#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_invgauss_inv_Tukey_1)))
  #modèle plein
round(-2*as.numeric(logLik(invgauss.inv_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_invgauss_inv_Tukey_1)))
```

### Loi Log Normale

Pour la fonction de lien "identité" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_lognorm_id_0)))
  #modèle plein
round(-2*as.numeric(logLik(lognorm.id_1)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_lognorm_id_1)))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_lognorm_id_Tukey_1)))
  #modèle plein
round(-2*as.numeric(logLik(lognorm.id_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_lognorm_id_Tukey_1)))
```

Pour la fonction de lien "inverse" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_lognorm_inv_0)))
  #modèle plein
round(-2*as.numeric(logLik(lognorm.inv_1)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_lognorm_inv_1)))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_lognorm_inv_Tukey_1)))
  #modèle plein
round(-2*as.numeric(logLik(lognorm.inv_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_lognorm_inv_Tukey_1)))
```

Pour la fonction de lien "log" :

```{r}
#Sans outlier, avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_lognorm_log_0)))
  #modèle plein
round(-2*as.numeric(logLik(lognorm.log_1)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_lognorm_log_1)))

#Avec méthode de Tukey et avec intéractions
  #modèle réduit à l'intercept
round(-2*as.numeric(logLik(mod0_lognorm_log_Tukey_1)))
  #modèle plein
round(-2*as.numeric(logLik(lognorm.log_Tukey)))
  #modèle both
round(-2*as.numeric(logLik(modBoth_lognorm_log_Tukey_1)))
```

# Modèle final

Parmi les modèles réalisés, la loi Gamma avec le lien "log" et la loi Log Normale sont les plus aptes à ajuster la variable "ClaimAmount" de nos données. Celles-ci n'entraînent pas de problème de divergence et proposent de nombreuses variables qui auraient un impact sur notre variable de sévérité.

Les plus variables les plus intéressantes et significatives sont :

-   "ClaimNbResp"

-   "ClaimNbNonResp"

-   "ClaimWindscreen"

D'autres variables ont également un impact mais leurs p valeurs sont beaucoup moins significatives comparées à ces trois variables. De plus, il est assez logique que le fait d'avoir eu plusieurs sinistres responsables, non responsables et des bris-de-glace les quatres années précédentes laisse à penser que notre assuré serait un "mauvais" conducteur et serait susceptible de rembourser cette année des montants supérieurs aux autres assurés.

Vérifions quand même si les modèles proposés permettent de prédire correctement nos variables sur le jeu de donnée "test"

## Prédiction et Estimation

```{r}
#Pour le modèle Gamma
estimation <- gamma.log_1$fitted.values
hist(estimation)

prediction <- predict.glm(gamma.log_1, newdata = test, type = "response")
hist(prediction)

summary(estimation)
summary(prediction)
```

On observe bien une tendance très proche entre l'estimation de nos données et la prédiction

```{r}
# Pour la loi Log Normale au lien identité
estimation <- lognorm.id_1$fitted.values
hist(estimation)

prediction <- predict.glm(lognorm.id_1, newdata = test, type = "response")
hist(prediction)

summary(estimation)
summary(prediction)
```

### RMSE

```{r}
RMSE_train <- sqrt(mean(lognorm.id$residuals^2))
RMSE_train
```

---
title: "GLM"
author: "Dudot Lucas - Lapaz Eudes - Moinard Benjamin - Nanoux Louis"
date: "2023-01-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = TRUE, message = FALSE, error = FALSE}
library(FactoMineR)
library(factoextra)
library(CASdatasets)
library(tidyverse)
library(MASS)
library(knitr)
library(ggplot2)
library(cowplot)
library(reshape2)
library(dplyr)
library(GGally)
library(corrplot)
library(carData) 
library(car)
library(questionr)
library(multcomp)
library(dplyr)
library(leaps)
library(TeachingDemos)
library(factoextra)
library(ROCR)
library(plotROC)
library(caret)
```

# GLM pour la variable coût

## I) Transformation de certaines variables en variables catégorielles

```{r}
data(freMPL5)
```

Notre variable "ClaimAmount" est une variable quantitative et représente le prix total des accidents survenus au cours de l'année pour chacun des assurés.

Cette variable prend ainsi une valeur nulle lorque la variable "ClaimInd" a la valeur nulle, c'est-à-dire si aucun accident n'est survenu et prend des valeurs positives dans le cas contraire.

```{r}
summary(freMPL5$ClaimAmount)
```

Seulement, nos données présentent des cas particuliés et isolés dans laquelle la variable ClaimAmount prend des valeurs négatives. Nous élimineront ces données dans la suite de notre étude de la variable et nous nous intéresserons aux valeurs que celle-ci peut prendre lorsqu'un incident a lieu.

Nous utiliserons également le même découpage réalisé lors de l'étude de la variable fréquence.

```{r}
#enlever les valeurs négatives
freMPL5 <- subset(freMPL5, freMPL5$ClaimAmount >= 0)

#passer en variables catégorielles
freMPL5$HasKmLimit <- factor(freMPL5$HasKmLimit)
freMPL5$ClaimInd <- factor(freMPL5$ClaimInd)

#segmentation des tranches d'âge
freMPL5$DrivAge_fact <- cut(freMPL5$DrivAge, c(20,25,30,35,40,45,50,58,65,120), include.lowest = TRUE)

#Découpage CSP
freMPL5$Categ <-  ifelse(freMPL5$SocioCateg %in% c("CSP46","CSP48"), "Categ1",
ifelse(freMPL5$SocioCateg %in% c("CSP50","CSP55"), "Categ2",
ifelse(freMPL5$SocioCateg %in% c("CSP60"),"Categ3",
ifelse(freMPL5$SocioCateg %in% c("CSP42","CSP1", "CSP66"),"Categ4","Categ0"))))
freMPL5$Categ = factor(freMPL5$Categ)

#découpage RiskArea
freMPL5$RiskArea <- ifelse(freMPL5$RiskArea %in% c(1,2,3,12,13), "ZoneRisque1",
ifelse(freMPL5$RiskArea %in% c(5,6,7,8,9), "ZoneRisque2",
ifelse(freMPL5$RiskArea %in% c(10,11), "ZoneRisque3",
ifelse(freMPL5$RiskArea %in% c(4), "ZoneRisque4", NA))))

freMPL5$RiskArea <- factor(freMPL5$RiskArea)
```

```{r}
summary(freMPL5$Categ)

```

Le coefficient de bonus-malus est réglementaire, ne faut-il pas le rajouter que plus tard dans la tarification ?

Nous allons faire un système à double pénalisation, "BonusMalus" sera pris en compte dans nos GLMs et notre grille de tarification.

## II) Première estimation de la loi de notre variable "ClaimAmount"

```{r, error = TRUE}
cout <- freMPL5[freMPL5$ClaimInd == 1,]
```

```{r}
summary(cout$ClaimAmount)
```

Dans un premier temps , on observe une répartition très inégale des montants des accidents. En plus d'une moyenne de 2277.22 et d'une médiane à 800.95, le montant maximal des accidents de notre jeu de données est de 95150.96.

```{r}
hist(cout$ClaimAmount)
plot(cout$ClaimAmount)
abline (a=60000,b=0, col ="red")
#on observe dans un premier temps deux valeurs extremes qui dépassent de 47 fois la moyenne.

#Etudions toujours la répartition de la variable de sévérité privé de ces deux valeurs extrêmes.
cout1 <- subset(cout, cout$ClaimAmount <60000)
hist(cout1$ClaimAmount)
plot(cout1$ClaimAmount)
abline (a=35000,b=0, col ="blue")
#Pour une étude non biaisée vers d'autres valeurs moins extrêmes, il serait également préferable de faire une étude sur des montants inférieurs à 35000€. Seulement sept observations ont été estimées supérieures à ce prix.

cout2 <- subset(cout, cout$ClaimAmount <35000)
hist(cout2$ClaimAmount)
plot(cout2$ClaimAmount)
```

### a) Estimation d'une loi

Dans notre étude sur la variable de sévérité ClaimAmount, nous allons essayer d'approcher la distribution de cette variable par une loi continue connue.

Nous utiliserons la méthode du qqplot

```{r}
#Approche par une loi Gamma
alpha = mean(cout$ClaimAmount)^2/var(cout$ClaimAmount)
beta = mean(cout$ClaimAmount)/var(cout$ClaimAmount)
qqplot (cout$ClaimAmount, qgamma ( ppoints (cout$ClaimAmount,3/8), shape =alpha, rate =beta),
        	xlab ="Prix des sinistres observés",
        main ="Graphique des quantiles pour les prix des sinistres (loi gamma).")
abline (a=0,b=1, col ="red")
```

La loi gamma semble très bien s'adapter à notre modèle. De plus, une divergence avec la loi est observée lorsque les valeurs sont supérieures à 35 000. Cela nous maintient dans l'idée d'étudier notre jeu de données aux montants inférieurs à 35000.

```{r}
qqplot (cout$ClaimAmount, qnorm ( ppoints (cout$ClaimAmount,3/8), mean =mean(cout$ClaimAmount), sd =sqrt(var(cout$ClaimAmount))),
        	xlab ="Prix des sinistres observés",
        main ="Graphique des quantiles pour les prix des sinistres (loi normale).")
abline (a=0,b=1, col ="red")
```

La loi normale ne semble pas être très adaptée à notre modèle

```{r}
#Approche par la loi log normale
fit_params <- fitdistr(cout2$ClaimAmount,"lognormal")
qqplot (cout2$ClaimAmount, qlnorm ( ppoints (cout2$ClaimAmount,3/8), mean = fit_params$estimate['meanlog'], sd = fit_params$estimate['sdlog']),
        	xlab ="Prix des sinistres observés",
        main ="Graphique des quantiles pour les prix des sinistres (loi log normale).")
abline (a=0,b=1, col ="red")
```

### b)Séparation en échantillon apprentissage et échantillon test

```{r}
cout3 <- subset(cout, cout$ClaimAmount <20000)
set.seed(123)
perm <- sample(nrow(cout3),80/100*nrow(cout3))
train <- cout3[perm,]
test <- cout3[-perm,]

```

## III) Etude des outliers

Cette partie sera consacrée à l'étude d'outliers. Cette dernière peut s'avérer utile pour avoir un modèle le plus efficient possible. Nous avons commencé à enlever des valeurs extrêmes en limitant le domaine d'étude aux sinistres de montant inférieur à 20000€. Affinons cette recherche grâce à d'autres méthodes mises à notre disposition.

### a) Méthode d'Hampel

```{r}
q= 3 
# calcule la borne inf de l'intervalle binf
borne_inf <- median(train$ClaimAmount) - q * mad (train$ClaimAmount) 
#mad représente la déviation absolue de la médiane
borne_inf 

# calcule la borne sup de l'intervalle bsup 
borne_sup <- median(train$ClaimAmount) + q * mad (train$ClaimAmount) 
borne_sup

#On renvoie les indices des outliers potentiels

indices_outliers <- which(train$ClaimAmount < borne_inf | train$ClaimAmount > borne_sup)
indices_outliers
length(indices_outliers)

#On renvoie les valeurs prises par nos outliers

valeurs_outliers <- train[indices_outliers,"ClaimAmount"]
valeurs_outliers

#Puis on retire les outliers de notre échantillon

train_Hampel=slice(train,-indices_outliers)
```

### b) Méthode de Tukey combiné à la méthode d'Hampel

Cette méthode se base sur l'écart interquartile et permet de détecter de potentiels outliers

```{r}
# Calculer l'écart interquartile (IQR)
iqr <- IQR(train_Hampel$ClaimAmount)

# Calculer les bornes de la méthode de Tukey
lower_bound <- quantile(train_Hampel$ClaimAmount, 0.25) - 1.5*iqr
upper_bound <- quantile(train_Hampel$ClaimAmount, 0.75) + 1.5*iqr

# Identifier les outliers
outliers_tukey_valeurs <- train_Hampel$ClaimAmount[train_Hampel$ClaimAmount < lower_bound | train_Hampel$ClaimAmount > upper_bound]

#On extrait les indices de ces outliers
outliers_tukey_indices <- which(train_Hampel$ClaimAmount < lower_bound | train_Hampel$ClaimAmount > upper_bound)

# Afficher les résultats
outliers_tukey_valeurs
length(outliers_tukey_valeurs)
outliers_tukey_indices

#On enlèves ces outliers de notre échantillon 

train_Hampel_Tukey=slice(train_Hampel,-outliers_tukey_indices)
```

### c) Méthode de Tukey

```{r}
# Calculer l'écart interquartile (IQR)
iqr_1 <- IQR(train$ClaimAmount)

# Calculer les bornes de la méthode de Tukey
lower_bound_1 <- quantile(train$ClaimAmount, 0.25) - 1.5*iqr
upper_bound_1 <- quantile(train$ClaimAmount, 0.75) + 1.5*iqr

# Identifier les outliers
outliers_tukey_valeurs_1 <- train$ClaimAmount[train$ClaimAmount < lower_bound | train$ClaimAmount > upper_bound]

#On extrait les indices de ces outliers
outliers_tukey_indices_1 <- which(train$ClaimAmount < lower_bound | train$ClaimAmount > upper_bound)

# Afficher les résultats
outliers_tukey_valeurs_1
length(outliers_tukey_valeurs_1)
outliers_tukey_indices_1

#On enlèves ces outliers de notre échantillon 

train_Tukey=slice(train,-outliers_tukey_indices_1)
```

Par la suite, nous nous servirons de ces méthodes dans nos glm pour affiner la qualité de prédiction de ces derniers.

### d) Existence d'éventuels autres outliers

Pour voir si d'autres outliers, nous nous servirons de la fonction "outliersTest". La méthode OutliersTest consiste à calculer la distance de chaque valeur de l'ensemble de données à la moyenne ou à la médiane de l'ensemble de données. Si cette dernière est plus élevée qu'un seuil prédéfini, la valeur sera considérée comme aberrante.

```{r}
outlierTest(gamma.id_Hampel)
```

## IV) Loi gamma

Nous allons faire un GLM avec la loi gamma et les liens identité, inverse et log.

### A) Lien inverse

#### 1) Echantillon sans étude d'outliers / sans intéraction

```{r}
gamma.inv_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = Gamma(link = "inverse"),start =rep(0.01,28))
summary(gamma.inv_0)
```

La commande "start =rep(0.01,28)" permet de donner une valeur inititale aux coefficients que l'on cherche à estimer. Nous verrons par la suite que nos modèles appliqués aux données issues de la méthode d'Hampel et du Tukey nous permettent de palier ce problème.

#### 2) Echantillon sans étude d'outliers / avec intéractions

Nous avons choisi de faire 3 intéractions sur un grand nombre testés, car il s'agit des plus significatives :

DrivAge_fact\*RiskArea ; MariStat\*ClaimNbResp ; RiskArea\*MariStat

```{r}
gamma.inv_1 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp 
+RiskArea*MariStat,data = train, family = Gamma(link = "inverse"),start =rep(0.01,56))
summary(gamma.inv_1)
```

Ce message d'erreur indique que l'algorithme n'a pas convergé. Nous verrons par la suite que les intéractions sont plus significatives pour d'autres liens et d'autres données.

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod_gamma_inv_0 <- glm(ClaimAmount ~ 1, data = train, family = Gamma(link = "inverse"))
summary(mod_gamma_inv_0)
```

```{r}
mod_gamma_inv_Both = step(gamma.inv_1, mod_gamma_inv_0, trace=F,direction = c('both'))
summary(modBoth_gamma_inv_Both)
```

Nous ne nous éterniserons pas davantage sur ce message d'erreur. En effet, cela marchera davantage avec d'autres données

##### RMSE

```{r}
RMSE_train <- sqrt(mean(mod_gamma_inv_Both$residuals^2))
RMSE_train
```

#### 4) Echantillon avec études d'outliers et intéractions : Hampel

```{r}
gamma.inv_Hampel_0<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp +RiskArea*MariStat,data = train_Hampel, family = Gamma(link = "inverse"))
summary(gamma.inv_Hampel_0)
```

Nous voyons que nous n'avons plus besoin de fournir un jeu de données de départ.

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod_gamma_inv_1 <- glm(ClaimAmount ~ 1, data = train_Hampel, family = Gamma(link = "inverse"))
summary(mod_gamma_inv_1)
```

```{r}
mod_gamma_inv_Both_1 = step(gamma.inv_Hampel_0, mod_gamma_inv_1, trace=F,direction = c('both'))
summary(mod_gamma_inv_Both_1)
```

L'écart d'AIC entre les modèle réduit à l'intercept et both n'est pas conséquent.

#### 5) Echantillon avec études d'outliers et intéractions : Tukey

```{r}
gamma.inv_Tukey_0<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp +RiskArea*MariStat,data = train_Tukey, family = Gamma(link = "inverse"))
summary(gamma.inv_Tukey_0)
```

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod_gamma_inv_2 <- glm(ClaimAmount ~ 1, data = train_Tukey, family = Gamma(link = "inverse"))
summary(mod_gamma_inv_2)
```

```{r}
mod_gamma_inv_Both_2 = step(gamma.inv_Tukey_0, mod_gamma_inv_2, trace=F,direction = c('both'))
summary(mod_gamma_inv_Both_2)
```

##### RMSE

```{r}
RMSE_train_Tukey_inv <- sqrt(mean(mod_gamma_inv_Both_2$residuals^2))
RMSE_train_Tukey_inv
```

### B) Lien log

#### 1) Echantillon sans étude d'outliers / sans intéraction

```{r}
gamma.log_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = Gamma(link = "log"))
summary(gamma.log_0)
```

#### 2) Echantillon sans étude d'outliers / sans intéraction

```{r}
gamma.log_1 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp 
+RiskArea*MariStat,data = train, family = Gamma(link = "log"))
summary(gamma.log_1)
```

##### Comparaison AIC entre le modèle réduit à l'intercept et plein

```{r}
mod_gamma_log_0 <- glm(ClaimAmount ~ 1, data = train, family = Gamma(link = "log"))
summary(mod_gamma_log_0)
```

```{r}
mod_gamma_log_Both = step(gamma.log_1, mod_gamma_log_0, trace=F,direction = c('both'))
summary(mod_gamma_log_Both)
```

Pas d'écart significatif entre les deux AIC.

##### RMSE

```{r}
RMSE_train <- sqrt(mean(mod_gamma_log_Both$residuals^2))
RMSE_train
```

#### 3) Echantillon avec étude d'outliers et intéractions : Tukey

```{r}
gamma.log_Tukey_0<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp +RiskArea*MariStat,data = train_Tukey, family = Gamma(link = "log"))
summary(gamma.log_Tukey_0)
```

##### AIC

```{r}
mod_gamma_log_2 <- glm(ClaimAmount ~ 1, data = train_Tukey, family = Gamma(link = "inverse"))
summary(mod_gamma_log_2)
```

```{r}
mod_gamma_log_Both_2 = step(gamma.log_Tukey_0, mod_gamma_log_2, trace=F,direction = c('both'))
summary(mod_gamma_log_Both_2)
```

##### RMSE

```{r}
RMSE_train_Tukey_log <- sqrt(mean(mod_gamma_log_Both_2$residuals^2))
RMSE_train_Tukey_log
```

### B) Lien Identité

#### 1) Echantillon sans outliers / sans intéraction

```{r}
gamma.id_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = Gamma(link = "identity"))
summary(gamma.id_0)
```

```{r}
mod_gamma_id_2 <- glm(ClaimAmount ~ 1, data = train, family = Gamma(link = "identity"))
AIC(mod_gamma_id_2)
```

```{r}
mod_gamma_id_Both_2 = step(gamma.id_0, mod_gamma_id_2, trace=F,direction = c('both'))
AIC(mod_gamma_id_Both_2)
```

#### 2) Echantillon sans outliers / avec intéractions

```{r}
gamma.id_1 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp 
+RiskArea*MariStat,data = train, family = Gamma(link = "identity"))
summary(gamma.id_1)
```

Ce message d'erreur apparaissant, nous allons davanateb nous focalier sur l'échantillon train_Tukey

#### 3) Echantillon avec étude d'outliers et intéractions : Tukey

```{r}
gamma.id_Tukey_0<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+RiskArea*MariStat,data = train_Tukey, family = Gamma(link = "identity"))
summary(gamma.id_Tukey_0)
```

#### 4) Echantillon avec étude d'outliers et intéractions : Hampel

```{r}
gamma.id_Hampel_0<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+RiskArea*MariStat,data = train_Hampel, family = Gamma(link = "identity"))
summary(gamma.id_Hampel_0)
```

#### 5) Echantillon avec étude d'outliers et intéractions : Hampel et Tukey

```{r}
gamma.id_Hampel_Tukey_0<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+RiskArea*MariStat,data = train_Hampel_Tukey, family = Gamma(link = "identity"))
summary(gamma.id_Hampel_Tukey_0)
```

Malgré l'étude d'outliers, aucun des trois échantillons ne semblement permettre la convergence de l'algorithme.

##### AIC

```{r}
mod_gamma_id_Hampel_Tukey_2 <- glm(ClaimAmount ~ 1, data = train_Hampel_Tukey, family = Gamma(link = "identity"))
AIC(mod_gamma_id_2)
```

```{r}
mod_gamma_id_Both_Hampel_Tukey_2 = step(gamma.id_Hampel_Tukey_0, mod_gamma_id_Hampel_Tukey_2, trace=F,direction = c('both'))
AIC(mod_gamma_id_Both_Hampel_Tukey_2)
```

### Test pour voir les erreurs avec un modèle Gamma

```{r, error = TRUE}
glm(ClaimAmount ~ MariStat+SocioCateg+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = cout, offset = log(Exposure), family = Gamma())
```

```{r, error = TRUE}
glm(ClaimAmount ~ MariStat+SocioCateg+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = cout, offset = log(Exposure), family = Gamma(), start = rep(0, 49))
```

### Prediction

```{r}
estimation <- gamma.log$fitted.values
hist(estimation)
```

```{r}
prediction <- predict.glm(gamma.log, newdata = test, type = "response")
hist(prediction)

```

## V) Loi Gaussienne Inverse

### A) Lien 1/mu\^2

#### 1) Echantillon sans outliers / sans interactions

```{r}
invgauss.mu_0 <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "1/mu^2"),start=rep(0.01,28))
summary(invgauss.mu_0)
```

##### AIC

```{r}
mod_invgauss_mu_0 <- glm(ClaimAmount ~ 1, data = train, family = inverse.gaussian(link = "1/mu^2"))
AIC(mod_invgauss_mu_0)
```

```{r}
mod_invgauss_mu_Both_0 = step(invgauss.mu_0, mod_invgauss_mu_0, trace=F,direction = c('both'),start=rep(0.01,56))
AIC(mod_invgauss_mu_Both_0)
```

#### 2) Echantillon sans outliers / avec interactions

```{r}
invgauss.mu_1<- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp 
+RiskArea*MariStat,data = train, family = Gamma(link = "1/mu^2"),start=rep(0.01,56))
summary(invgauss.mu_1)
```

##### AIC

```{r}
mod_invgauss_mu_1 <- glm(ClaimAmount ~ 1, data = train, family = inverse.gaussian(link = "1/mu^2"))
AIC(mod_invgauss_mu_1)
```

```{r}
mod_invgauss_mu_Both_1 = step(invgauss.mu_1, mod_invgauss_mu_1, trace=F,direction = c('both'),start=rep(0.01,56))
AIC(mod_invgauss_mu_Both_1)
```

##### RMSE

```{r}
RMSE_train_invgauss <- sqrt(mean(mod_invgauss_mu_Both_1$residuals^2))
RMSE_train_invgauss
```

#### 3) Etude avec intéractions et outliers : Tukey

```{r}
invgauss.mu_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea+MariStat*ClaimNbResp+RiskArea*MariStat, data = train_Tukey, family = inverse.gaussian(link = "1/mu^2"))
summary(invgauss.mu_Tukey)
```

##### AIC

```{r}
mod_invgauss_mu_Tukey <- glm(ClaimAmount ~ 1, data = train_Tukey, family = inverse.gaussian(link = "1/mu^2"))
AIC(mod_invgauss_mu_Tukey)
```

```{r}
mod_invgauss_mu_Tukey_Both = step(invgauss.mu_Tukey, mod_invgauss_mu_Tukey, trace=F,direction = c('both'))
summary(mod_invgauss_mu_Tukey_Both)
```

##### RMSE

```{r}
RMSE_train_invgauss_1 <- sqrt(mean(mod_invgauss_mu_Tukey_Both$residuals^2))
RMSE_train_invgauss_1
```

```{r}
invgauss.id <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "identity"),na.action = na.exclude)

invgauss.inv <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "inverse"),na.action = na.exclude)

invgauss.log <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "log"),,na.action = na.exclude)
```

### B) Lien Identité, inverse et log

#### 1) Echantillon sans outliers / sans interactions

```{r}
invgauss.id <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "identity"),na.action = na.exclude)
#(na.action = na.exclude) permet d'effectuer le GLM sans prendre compte des possibles données manquantes de notre échantillon train
```

```{r}
invgauss.inv <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "inverse"),na.action = na.exclude)
```

Ce message d'erreur apparait suite à la présence de données avec des valeurs Inf, manquantes, indéfinies ou non numériques mais aussi lorsque les variables ne sont pas appropriées pour la regression logistique de notre modèle. Or nous n'avons pas de valeurs manquantes exceptées pour la variable "RecordBeg" d'après le code suivant :

```{r}
dataSansRecordBeg <- train[, -4]
if (sum(is.na(dataSansRecordBeg)) > 0) {
  NaMiss <- 1
  #présence d'au moins une valeur manquante
} else {
  NaMiss <- 0
  #abscence de valeurs manquantes
}
print(NaMiss)
```

Les liens "identité", "inverse" et "log" pour un GLM défini avec la loi gaussienne inverse ne sont pas compatibles avec notre jeu de données "train"

```{r}
invgauss.log <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "log"),na.action = na.exclude)
```

```{r}
invgauss.log$converged
```

Essayons de voir s'il est possible d'obtenir des GLM à l'aide des méthodes des outliers.

#### 3)Echantillon avec outliers

```{r}
invgauss.id_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel_Tukey, family = inverse.gaussian(link = "identity"),na.action = na.exclude)

```

```{r}
invgauss.log_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel_Tukey, family = inverse.gaussian(link = "log"),na.action = na.exclude)
```

Le lien "identité" et "log" renvoient le même message d'erreur pour chaque méthode des outliers et ne sont pas appropriés pour une regression logistique de la loi inverse gaussienne.

```{r}
invgauss.inv_Tukey <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Tukey, family = inverse.gaussian(link = "inverse"))
summary(invgauss.inv_Tukey)

```

#### a) Comparaison entre Modèle plein et vide

```{r}
mod_invgauss.inv_0 <- glm(ClaimAmount ~ 1, data = train_Tukey, family = inverse.gaussian(link = "inverse"))
summary(mod_invgauss.inv_0)
```

```{r}
mod_invgauss.inv_Both = step(invgauss.inv_Tukey, mod_invgauss.inv_0, trace=F,direction = c('both'))
summary(mod_invgauss.inv_Both)
```

#### b) Prediction

## Loi Log Normale

### I) Modeles avec étude des outliers

#### a) Méthode Tukey

```{r}
lognorm.id_Tukey <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Tukey, family = gaussian(link = "identity"))
summary(lognorm.id_Tukey)
```

#### b) Méthode Hampel

```{r}
lognorm.id_Hampel <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel, family = gaussian(link = "identity"))
summary(lognorm.id_Hampel)
```

#### c) Méthode Tukey-Hampel

```{r}
lognorm.id_Hampel_Tukey <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train_Hampel_Tukey, family = gaussian(link = "identity"))
summary(lognorm.id_Hampel_Tukey)
```

Les résultats semblent moins concluant que pour le modèle sans étude d'outliers

### II) Modèles avec intéractions

#### a) lien identité

```{r}
lognorm.id_Tukey_1 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea + RiskArea*MariStat + MariStat*ClaimNbResp, data = train_Tukey, family = gaussian(link = "identity"))
summary(lognorm.id_Tukey_1)
```

```{r}
mod0_lognorm_id_1 <- glm(log(ClaimAmount) ~ 1, data = train_Tukey, family = gaussian(link = "identity"))
modBoth_lognorm_id_1 = step(lognorm.id_Tukey_1, mod0, trace=F,direction = c('both'))
summary(mod0_lognorm_id_1)
summary(modBoth_lognorm_id_1)
```

#### b) lien inverse

```{r}
lognorm.inv_Tukey_1 <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea + RiskArea*MariStat + MariStat*ClaimNbResp, data = train_Tukey, family = gaussian(link = "inverse"))
summary(lognorm.inv_Tukey_1)
```

```{r}
mod0_lognorm_inv_1 <- glm(log(ClaimAmount) ~ 1, data = train_Tukey, family = gaussian(link = "inverse"))
modBoth_lognorm_inv_1 = step(lognorm.inv_Tukey_1, mod0, trace=F,direction = c('both'))
summary(mod0_lognorm_inv_1)
summary(modBoth_lognorm_inv_1)
```

### II) Modele Lucas

```{r}
lognorm.id <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact+DrivAge_fact*RiskArea + RiskArea*MariStat + MariStat*ClaimNbResp, data = train, family = gaussian(link = "identity"))
summary(lognorm.id)
```

```{r}
summary(lognorm.id)
```

```{r}
lognorm.inv <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = gaussian(link = "inverse"))

summary(lognorm.inv)

lognorm.log <- glm(log(ClaimAmount) ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = gaussian(link = "log"))

summary(lognorm.log)

#On récupère les estimateurs de ce modèle sous forme de liste 

coeffcients_lognorm.log=coef(lognorm.log)
coeffcients_lognorm.log
```

```{r}
summary(lognorm.inv)
summary(lognorm.log)
```

### Both, Backward and Forward

```{r}
mod0_lognorm_id_0 <- glm(log(ClaimAmount) ~ 1, data = train, family = gaussian(link = "identity"))
summary(mod0_lognorm_id_0)
```

```{r}
modBoth_lognorm_id_0 = step(lognorm.id, mod0, trace=F,direction = c('both'))
summary(modBoth_lognorm_id_0)
```

```{r}
modBack = step(lognorm.id, mod0, trace=F,direction = c('backward'))
summary(modBack)
```

```{r}
modFor = step(lognorm.id, mod0, trace=F,direction = c('forward'))
summary(modFor)
```

### Prediction

```{r}
estimation <- lognorm.id$fitted.values
hist(estimation)

prediction <- predict.glm(lognorm.id, newdata = test, type = "response")
hist(prediction)
```

### RMSE

```{r}
RMSE_train <- sqrt(mean(modBoth$residuals^2))
RMSE_train
```

# GLM pour la variable fréquence

On remarque que la variable à étudier vaut uniquement 0 ou 1 (indique si l'assuré a eu un sinistre ou non). Nous allons donc dans un premier temps la modéliser par une loi de Bernoulli. Cette fois-ci, on prend le jeu de données complet (pas uniquement les assurés ayant eu des sinistres évidemment, contrairement à la partie précédente).

Habituellement, on utilise une approche fréquence-sévérité où la fréquence est le nombre d'accidents que l'assuré a obtenu. Cependant, on aura ici que la fréquence est soit 1, soit 0 selon le fait qu'il ait eu un sinistre ou pas.

Nous aurons donc la formule suivante :

$$
E[X_i]=E[F_i] \cdot E[B_i]
$$

avec $B_i$ la variable de coût moyen et $F_i$ la variable de fréquence qui sera une $Ber(q_i)$ donc

$$
E[F_i] = q_i
$$

d'où

$$
E[X_i]=q_i \cdot E[B_i]
$$

**Remarque :**

Les variables ClaimNbResp, ClaimNbNonResp, ClaimNbParking, ClaimNbFireTheft, ClaimNbWindscreen, OutUseNb traitent des sinistres passés durant les 4 années précédentes. Ils permettront peut-être de déterminer si l'assuré a des risques d'avoir de nouveau ce genre de sinistres qui sont plus ou moins coûteux selon leur classification.

```{r}
#on veut reprendre les lignes où ClaimAmout pouvait aussi être nul
data(freMPL5)
freMPL5$HasKmLimit <- factor(freMPL5$HasKmLimit)
freMPL5$RiskArea <- factor(freMPL5$RiskArea)
freMPL5$ClaimInd <- factor(freMPL5$ClaimInd)

freMPL5$DrivAge_fact <- cut(freMPL5$DrivAge, c(20,25,30,35,40,45,50,58,65,120), include.lowest = TRUE)
```

```{r}
#glm(ClaimInd ~ MariStat+SocioCateg+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = freMPL5, offset = Exposure, family = binomial(link = logit))
```

```{r}
#bin.prob <-glm(ClaimInd ~ MariStat+SocioCateg+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = freMPL5, offset = Exposure, family = binomial(link = probit) )
#summary(bin.prob)
```

Le ratio "residual deviance/ degrés de liberté" est de 0.57190... qui est inférieur à 1, il n'y aurait pas de problème d'overfeating. Il ne serait pas nécessaire de passer par les quasi-lois mais faisons le quand même.

```{r}
#glm(ClaimInd ~ MariStat+SocioCateg+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = freMPL5, offset = Exposure, family = quasibinomial(link = logit) )
```

Il y a ici encore plein de catégories socio-professionnelles à enlever ou regrouper.

```{r}
freMPL5 <- subset(freMPL5, freMPL5$SocioCateg != "CSP30" & freMPL5$SocioCateg !="CSP45" & freMPL5$SocioCateg !="CSP63" & freMPL5$SocioCateg !="CSP61")

perm <- sample(nrow(freMPL5),80/100*nrow(freMPL5))
freMPL5.train <- freMPL5[perm,]
freMPL5.test <- freMPL5[-perm,]
```

```{r}
summary(freMPL5.train$ClaimInd)
summary(freMPL5.test$ClaimInd)
```

```{r}
#bin.log <- glm(ClaimInd ~ MariStat+SocioCateg+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = freMPL5.train, offset = Exposure, family = binomial(link = logit))
#summary(bin.log)
```

```{r}
#prediction <- predict.glm(bin.log, newdata = freMPL5.test, type = "response")
#summary(prediction)
#hist(prediction)
```

```{r}
#estimation <- bin.log$fitted.values
#summary(estimation)
#hist(estimation)
```

problème: dans SocioCateg, il y a CSP30 qui apparait dans test mais pas dans train

## Methode backward, forward, both

```{r}
mod0 <- glm(ClaimInd ~ 1, data = freMPL5.train, offset = Exposure, family = binomial(link = logit))
```

```{r}
modFor=step(bin.log, mod0, trace=F,direction = c('forward'))
summary(modFor)
```

```{r}
modBack=step(bin.log, mod0, trace=F,direction = c('backward'))
summary(modBack)
```

```{r}
modBoth=step(bin.log, mod0, trace=F,direction = c('both'))
summary(modBoth)
```

```{r}
summary(modBoth)
```

## RMSE (root mean squared error)

```{r}
RMSE_train <- sqrt(mean(modBoth$residuals^2))
RMSE_train
```

```{r}
bin.log2 <- glm(ClaimInd ~ SocioCateg+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+RiskArea+BonusMalus, data = freMPL5.test, offset = Exposure, family = binomial(link = logit))

RMSE_test <- sqrt(mean(bin.log2$residuals^2))
RMSE_test
```

## MAE (mean absolute error)

```{r}
MAE_train <- mean(abs(modBoth$residuals))
MAE_train
```

## AUC, Courbe ROC

### Sur l'échantillon train

```{r}
pred=prediction(bin.log$fitted.values, freMPL5.train$ClaimInd)
perf=performance(pred,"tpr", "fpr")

auc_ROCR <- performance(pred, measure = "auc")
(auc_ROCR <- round(auc_ROCR@y.values[[1]],3) )
```

### Sur l'échantillon test

```{r}
prev_step <- predict(modBoth,newdata=freMPL5.test,type="response")
prev_prob <- data.frame(complet=predict(bin.log,newdata=freMPL5.test, type="response"),step=predict(modBoth,newdata=freMPL5.test,type="response"))
head(round(prev_prob,3), n=3)
```

```{r}
prev_class <- apply(prev_prob>0.5,2,factor,labels=1)
head(prev_class, n=3)
```

```{r}
mean(as.factor(prev_class[,1])==freMPL5.test$ClaimInd)
```

```{r}
mean(as.factor(prev_class[,2])==freMPL5.test$ClaimInd)
```

## Matrice de confusion

```{r}
score <- ifelse(predict(bin.log,freMPL5.test,type="response") >.3, "sinistre","sans sinistre")
confusion.mat = table(freMPL5.test$ClaimInd, score)  
fauxneg = confusion.mat[2,1]
fauxpos = confusion.mat[1,2]
vraisneg = confusion.mat[1,1]
vraispos = confusion.mat[2,2]
(txerr = (fauxneg+fauxpos) / (fauxneg+fauxpos+vraisneg+vraispos))
```

taux d'erreur de 10% environ

```{r}
sensibilite <- vraispos / (vraispos + fauxneg)   
precision <- vraispos / (vraispos + fauxpos) 
specificite <- vraisneg / (vraisneg + fauxpos)
(danger <- fauxneg / (fauxneg+vraisneg))
```

Ce modèle va considérer que 9,6% des non sinistrés aurait un sinistre

```{r}
confusion.mat
```

## Cross Validation

```{r}
fit.control <- trainControl(method = "repeatedcv", number = 5, repeats = 10)

fit <- train(ClaimInd ~ MariStat + Categ + VehUsage + HasKmLimit + 
    ClaimNbResp + ClaimNbNonResp + ClaimNbParking + ClaimNbFireTheft + 
    ClaimNbWindscreen + OutUseNb + RiskArea + BonusMalus + DrivAge_fact,
    data = freMPL5.train, method = "glm", 
    family = "binomial", trControl = fit.control)
```

```{r}
invgauss.log <- glm(ClaimAmount ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = inverse.gaussian(link = "log"),start=rep(0.01,28))
```

```{r}
summary(train$ClaimAmount)
summary(train$Categ)
summary(train$MariStat)
summary(train$VehUsage)
summary(train$HasKmLimit)
summary(train$ClaimNbResp)
summary(train$ClaimNbNonResp)
summary(train$ClaimNbParking)
summary(train$ClaimNbFireTheft)
summary(train$ClaimNbWindscreen)
summary(train$BonusMalus)
summary(train$RiskArea)
summary(train$DrivAge_fact)
```

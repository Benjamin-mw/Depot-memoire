---
title: "GLM_ClaimInd"
author: "Dudot Lucas - Lapaz Eudes - Moinard Benjamin - Nanoux Louis"
date: "2023-02-28"
output:
  pdf_document: default
  html_document: default
---

Début habituel pour le code :

```{r include = FALSE}
#Packages
library(tables); library(ggExtra) ; library(FactoMineR) ; library(factoextra) ; library(CASdatasets)
library(tidyverse) ; library(MASS) ; library(knitr) ; library(ggplot2) ; library(cowplot)
library(reshape2) ; library(dplyr) ; library(GGally) ; library(corrplot) ; library(carData) 
library(car) ; library(questionr) ;library(multcomp) ; library(dplyr) ; library(leaps)
library(TeachingDemos) ; library(FactoMineR) ; library(factoextra) ; library(ROCR) ; library(plotROC)
library(graphics)
library(caret)

#Import jeu de données
data(freMPL5)
summary(freMPL5)

#Création d'une variable de sinistralité
freMPL5$Sinistres = freMPL5$ClaimInd/freMPL5$Exposure
freMPL5$Sinistres2 = round(freMPL5$Sinistres)

#Ajustement type des variables
freMPL5$HasKmLimit <- factor(freMPL5$HasKmLimit)
freMPL5$RiskArea <- factor(freMPL5$RiskArea)
freMPL5$OutUseNb <- as.numeric(freMPL5$OutUseNb)

#Suppression des valeurs négatives
freMPL5 <- subset(freMPL5, freMPL5$ClaimAmount >= 0)

#Segmentation des tranches d'âge
freMPL5$DrivAge_fact <- cut(freMPL5$DrivAge, c(20,25,30,35,40,45,50,58,65,120), include.lowest = TRUE)

#Découpage CSP
freMPL5$Categ = 0
freMPL5$Categ[freMPL5$SocioCateg == "CSP50"] = 3
freMPL5$Categ[freMPL5$SocioCateg == "CSP55"] = 3
freMPL5$Categ[freMPL5$SocioCateg == "CSP60"] = 4
freMPL5$Categ[freMPL5$SocioCateg == "CSP1"] = 1
freMPL5$Categ[freMPL5$SocioCateg == "CSP42"] = 1
freMPL5$Categ[freMPL5$SocioCateg == "CSP46"] = 2
freMPL5$Categ[freMPL5$SocioCateg == "CSP48"] = 2
freMPL5$Categ[freMPL5$SocioCateg == "CSP66"] = 1
freMPL5$Categ = factor(freMPL5$Categ)

freMPL5$Risque = 0
freMPL5$Risque[freMPL5$RiskArea == "5"] = 1
freMPL5$Risque[freMPL5$RiskArea == "6"] = 1
freMPL5$Risque[freMPL5$RiskArea == "7"] = 1
freMPL5$Risque[freMPL5$RiskArea == "8"] = 1
freMPL5$Risque[freMPL5$RiskArea == "9"] = 1
freMPL5$Risque[freMPL5$RiskArea == "10"] = 2
freMPL5$Risque[freMPL5$RiskArea == "11"] = 3
freMPL5$Risque[freMPL5$RiskArea == "4"] = 4
freMPL5$Risque = factor(freMPL5$Risque)
```

```{r}
summary(freMPL5$Sinistres2)
```

```{r}
set.seed(seed = 2023)
echantillon <- sample(c(TRUE, FALSE), nrow(freMPL5), replace=TRUE, prob=c(0.8,0.2))
train  <- freMPL5[echantillon, ]
test   <- freMPL5[!echantillon, ]
```

# 1) Modélisation de `ClaimInd` (approche binomiale)

L'objectif de cette étude est d'expliquer "ClaimInd" (représenter par la variable $Y$) grâce à $p$ variables explicatives que nous déterminerons.

Le code ci-dessous permet de savoir que l'évènement rare est "l'assuré a eu un sinistre". Par conséquent, on affecte la valeur 1 à cet évènement et 0 sinon (comme cela est déjà codé).

$Y$ est donc à valeurs dans $\text{{0;1}}$. La loi choisie pour cette modélisation est donc une loi de Bernouilli, avec comme fonction de lien canonique la fonction $logit$.

```{r}
Train_Contingence <- table(train$ClaimInd, train$ClaimInd)

x=c(Train_Contingence[1,1],Train_Contingence[2,2])
labels=c("Sans sinistre","Sinistre")
df=data.frame(x, labels)

ggplot(df, aes(x="", y=x, fill=labels)) +geom_bar(width = 1, stat ="identity") + coord_polar("y", start=0) +theme_void()+ggtitle("Sans/Avec sinistre")
```

La première étape dans la sélection de variables explicatives est l'étude des corrélations entre ses dernières.

Nous avons déjà fait cette étape dans la première partie donc nous allons donner directement le modèle.

Nous prendrons dans un premier temps toutes les variables sauf RecordBeg, RecordEnd, Gender (interdit par la législation française.

Afin de sélectionner au mieux notre modèle, nous devons introduire un critère de sélection.

Le critère $AIC$ d'un modèle $[m]$ est

$$
AIC(m)=\frac{n}{2}\log(SCR(m))+m
$$

avec $SCR(m)=||P_mY-Y||^2$ et $n$ le nombre d'observations. On choisit un modèle $[m]$ qui minimise l'$AIC$. Afin de déterminer le "meilleur" modèle pour notre étude, nous utiliserons la méthode "both". Cette dernière part de l'intercept et ajoute/enlève les variables une à une tout en comparant selon le critère $AIC$.

Nous allons introduire plusieurs modèles. Un modèle vide puis des modèles pleins utilisant différentes fonctions de lien.

### Lien log

```{r, message = FALSE, warning = FALSE}

mod0 <- glm(ClaimInd ~ 1, data = train, family = binomial(link = log))
summary(mod0)
```

```{r}
2*as.numeric(logLik(mod0))
```

```{r}
modFull <- glm(ClaimInd ~ MariStat+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact+Categ, data = train, family = binomial(link = log))
summary(modFull)
```

```{r}
2*as.numeric(logLik(modFull))
```

```{r}
modBoth = step(modFull, mod0, trace=F,direction = c('both'))
summary(modBoth)
```

```{r}
2*as.numeric(logLik(modBoth))
```

Grâce à cette méthode nous obtenons un candidat pour notre modélisation.

### Lien logit (lien canonique)

```{r}
mod0 <- glm(ClaimInd ~ 1, data = train, family = binomial(link = logit))
summary(mod0)
```

```{r}
modFull <- glm(ClaimInd ~ MariStat+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+Categ+DrivAge_fact, data = train, family = binomial(link = logit))
summary(modFull)
```

```{r}
2*as.numeric(logLik(modFull))
```

```{r}
modBoth_Bin <- step(modFull, mod0, trace = F, direction = c('both'))
summary(modBoth_Bin)
```

### Lien probit

```{r}
mod0 <- glm(ClaimInd ~ 1, data = train, family = binomial(link = "probit"))
summary(mod0)
```

```{r}
modFull <- glm(ClaimInd ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train, family = binomial(link = probit))
summary(modFull)
```

```{r}
2*as.numeric(logLik(modFull))
```

### Lien cauchit

```{r}
modFull <- glm(ClaimInd ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train, family = binomial(link = cauchit))
summary(modFull)
```

```{r}
2*as.numeric(logLik(modFull))
```

### Lien cloglog

```{r}
modFull <- glm(ClaimInd ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train, family = binomial(link = cloglog))
summary(modFull)
```

```{r}
2*as.numeric(logLik(modFull))
```

## Etude de potentiels outliers

Un élément important à prendre en compte dans l'analyse des données est le traitement des outliers. Voyons si nous observons des candidats potentiels par lecture graphique

```{r}
plot(modBoth)
```

Test pour voir si il y a des outliers :

```{r}
influenceIndexPlot(modBoth)

outlierTest(modBoth)
```

Si p-Bonferroni \>0,05 alors on conserve l'hyptohèse que ce n'est pas un outlier.

Il n'y a donc pas d'outlier ici dans ce modèle.

## Prédiction avec le modèle binomial

### Evaluation du modèle sur les données tests

```{r}
estimation <- modBoth$fitted.values
hist(estimation)
```

### Utilisation de métriques de comparaison

#### RMSE

```{r}
RMSE_train <- sqrt(mean(modBoth$residuals^2))
RMSE_train
```

### AUC

#### Sur le jeu de données train

```{r}
pred=prediction(modBoth$fitted.values, train$ClaimInd)
perf=performance(pred,"tpr", "fpr")

auc_ROCR <- performance(pred, measure = "auc")
(auc_ROCR <- round(auc_ROCR@y.values[[1]],3) )
```

#### Sur le jeu de données test

```{r warning = FALSE}
prev_step <- predict(modBoth,newdata=test,type="response")
prev_prob <- data.frame(complet=predict(modFull,newdata=test, type="response"),step=predict(modBoth,newdata=test,type="response"))
head(round(prev_prob,3), n=3)
prev_class <- ifelse(prev_prob>0.2, 1, 0)
head(prev_class, n=3)
mean(as.factor(prev_class[,1])==test$ClaimInd)
mean(as.factor(prev_class[,2])==test$ClaimInd)


df_roc <- prev_prob %>% mutate(obs=as.numeric(test$ClaimInd)) %>% gather(key=methode,value=score,complet,step)
ggplot(df_roc, aes(m=score, d=obs,color=methode))+ geom_roc()
```

### Table de confusion

#### Sur le jeu de données train

```{r}
estimation <- modBoth$fitted.values
hist(estimation)
score <- ifelse(predict(modBoth,train,type="response") >.1, 1, 0)
confusion.mat = table(train$ClaimInd, score)  
fauxneg = confusion.mat[2,1]
fauxpos = confusion.mat[1,2]
vraisneg = confusion.mat[1,1]
vraispos = confusion.mat[2,2]
(txerr = (fauxneg+fauxpos) / (fauxneg+fauxpos+vraisneg+vraispos))

sensibilite <- vraispos / (vraispos + fauxneg)   
precision <- vraispos / (vraispos + fauxpos) 
specificite <- vraisneg / (vraisneg + fauxpos)

confusion.mat
```

#### Sur le jeu de données test

```{r}
estimation <- modBoth$fitted.values
hist(estimation)
score <- ifelse(predict(modBoth,test,type="response") >.2, 1, 0)
confusion.mat = table(test$ClaimInd, score)  
fauxneg = confusion.mat[2,1]
fauxpos = confusion.mat[1,2]
vraisneg = confusion.mat[1,1]
vraispos = confusion.mat[2,2]
(txerr = (fauxneg+fauxpos) / (fauxneg+fauxpos+vraisneg+vraispos))
sensibilite <- vraispos / (vraispos + fauxneg)   
precision <- vraispos / (vraispos + fauxpos) 
specificite <- vraisneg / (vraisneg + fauxpos)

confusion.mat
```

## Cross Validation

```{r}
fit.control <- trainControl(method = "repeatedcv", number = 5, repeats = 10)

fit <- train(ClaimInd ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact,
    data = train, method = "glm", 
    family = "binomial", trControl = fit.control)

summary(fit)
```

# 2) Modélisation de `Sinistres2` (variable dans $\mathbb{N}$)

## a) Modélisation avec une Poisson

```{r}
summary(freMPL5$Sinistres)
bornes = seq(0,501,1)
hist(freMPL5$Sinistres)
hist(freMPL5$Sinistres, breaks=bornes, xlim=c(0,10))
hist(freMPL5$Sinistres, breaks=bornes, xlim=c(0,10), ylim = c(0,2000))
```

### Lien log (lien canonique)

```{r warning= FALSE}
mod0_2 <- glm(Sinistres2 ~ 1, data = train, family = poisson(link = "log"))
summary(mod0_2)
```

```{r}
-2*as.numeric(logLik(mod0_2))
```

```{r}
modFull_2 <- glm(Sinistres2 ~ MariStat+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+BonusMalus+Risque+DrivAge_fact+Categ, data = train, family = poisson(link = "log"))
summary(modFull_2)
```

Avec les intéractions entre DrivAge_fact et Categ, cela permet d'obtenir un meilleur critère d'AIC tout en conservant un temps de calcul cohérent.

```{r warning = FALSE}
modBoth_2 = step(modFull_2, mod0_2, trace=F, direction = c('both'))
summary(modBoth_2)
```

Remarque : Certaines interactions ont un coefficient indefini car aucun individu ne possède ces caractères dans l'échantilllon `train`.

D'autres une p-value très faible mais un coefficient élevé (en valeur absolue). Cela veut dire qu'il y a pas trop peu d'individus dans l'échantillon `train`. Nous devrons faire attention à cela puisque ça risque de mener à un surapprentissage. Nous ne conserverons donc que les interactions qui sont suffisamment représentatives dans l'échantillon `freMPL5`.

Cependant, continuons avant cela d'explorer les modèles. Ensuite nous en sélectionnerons un et nous l'améliorerons.

```{r}
plot(modBoth_2)
```

```{r}
lmb = mean(freMPL5$Sinistres2)
qqplot (freMPL5$Sinistres2, qpois(ppoints(freMPL5$Sinistres2), lambda = lmb),
        	xlab ="Sinistralité observées",
        main ="Graphique des quantiles pour la sinistralité.", xlim = c(0,50))
abline (a=0,b=1, col ="red")
```

Remarque : Nous avons tronquer xlim afin d'avoir une interprétation possible et visuelle. Sinon, il y avait quelques éléments qui allait bien trop loin (valeurs trop extrèmes).

Avec ce graphique des qqplot. On remarque bien que la loi de Poisson n'est pas adaptée à cette modélisation. En effet, il y a quelques observations qui sont très élevés, qui faussent la moyenne (appelée lmb ici qui est aussi le paramètre de la loi). Alors nous allons tenter de modéliser en enlevant dans un premier temps les données qui dépassent un certain seuil.

```{r}
RMSE_2_train <- sqrt(mean(modBoth_2$residuals^2))
RMSE_2_train
```

### Lien identité

```{r}
mod0_identité <- glm(Sinistres2 ~ 1, data = train, family = poisson(link = "identity"))
summary(mod0_identité)
```

```{r}
#modFull_identité <- glm(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, family = poisson(link = "identity"))
#summary(modFull_identité)
```

Il y a une erreur. Est-ce par rapport au fait qu'il ne pervient pas à trouver des valeurs pour les coefficients et donc que la méthode n'est pas convergente ?

### Lien sqrt

Remarque : d'après la documentation R, on ne pourra pas utiliser d'autres liens car "the `poisson` family accepts the links `log`, `identity`, and `sqrt`".

```{r}
mod0_sqrt <- glm(Sinistres2 ~ 1, data = train, family = poisson(link = "sqrt"))
summary(mod0_sqrt)
```

```{r}
modFull_sqrt <- glm(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train, family = poisson(link = "sqrt"))
summary(modFull_sqrt)
```

```{r}
modBoth_sqrt = step(modFull_sqrt, mod0_sqrt, trace = F, direction = c("both"))
summary(modBoth_sqrt)
```

On remarque que beaucoup de variables ont été enlevées ici pour maximiser l'AIC. Cependant, nous pouvons remarquer que l'AIC reste inférieur à celui obtenu avec le lien canonique log.

## b) Modélisation avec une Binomiale Négative

Utiliser `glm.nb`.

```{r}
modBN_0 <- glm.nb(Sinistres2 ~ 1, data = train)
summary(modBN_0)
```

```{r}
-2*as.numeric(logLik(modBN_0))
```

```{r}
modBN_Full <- glm.nb(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train)
summary(modBN_Full)
```

## c) Modélisation avec une Quasi-Poisson

```{r warning= FALSE}
mod0_3 <- glm(Sinistres2 ~ 1, data = train, family = quasipoisson(link = "log"))
summary(mod0_3)
```

```{r warning= FALSE}
modFull_3 <- glm(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train, family = quasipoisson(link = "log"))
summary(modFull_3)
```

Ici, l'AIC n'étant pas défini, on ne peut pas utiliser une méthode Both, Backward ou Forward classique avec ce critère.

```{r}
RMSE_3_train <- sqrt(mean(modFull_3$residuals^2))
RMSE_3_train
```

Cette modélisation ne change pas vraiment de la modélisation de Poisson classique puisqu'il n'y a pas de surdispersion dans les données.

# 3) Choix final de la modélisation et amélioration du modèle

En comparant les modèles vides avec les modèles pleins, on remarque que c'est le modèle de Poisson qui améliore le plus le critère de l'AIC. Nous allons donc choisir ce modèle. Nous sommes conscients que ce modèle ne fit pas complètement aux données et c'est pour cela que nous allons essayer de l'améliorer en cherchant des interactions cohérentes ou en utilisant uniquement certaines données.

## a) Interactions

Comme dit précédemment, la variable `Gender` qui donne le genre de l'assuré ne peut être utilisée explicitement dans le calcul de la prime d'un assuré en France. Nous décidons donc de ne pas en tenir compte dans ce mémoire même si l'information pourrait être utile.

Cherchons quelques intéractions cohérentes qui permettraient d'améliorer le modèle et comparons les avec le modèle plein classique. Notons que nous ne pourrons pas garder toutes les intéractions. En effet, si nous faisions cela, nous ferions de l'overfitting car alors certaines données seraient en trop petit nombre dans certaines catégories croisées, ce qui rendrait le modèle très dépendant de l'échantillon

Pour rappel, voici le modèle normal que nous allons nommer différemment.

```{r}
mod <- glm(Sinistres2 ~ ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+BonusMalus+DrivAge_fact+Risque+MariStat+HasKmLimit+Categ+VehUsage, data = train, family = poisson(link = "log"))
summary(mod)
```

Après avoir fait plusieurs interactions (tout en gardant un nombre interprétable de variables finales), nous remarquons que certaines interactions permettent d'améliorer le critère de l'AIC :

-   `Categ2:MariStatOther` et `Categ3:MariStatOther`

-   `Risque1:DrivAge_fact(45,50]` mais représente que 53 données donc c'est trop peu pour éviter le sur-apprentissage.

-   `Risque1:DrivAge_fact(35,40]` et `Risque2:DrivAge_fact(35,40]` et `Risque3:DrivAge_fact(35,40]` et `Risque4:DrivAge_fact(35,40]`

-   `Categ1 * DrivAge_fact` et `Categ3 * DrivAge_fact`

-   `Categ1:VehUsageProfessional` et `Categ3:VehUsageProfessional run`

    On peut noter que l'interaction `Risque*Categ` permet d'obtenir quelques autres variables significatives mais les variables de base perdent alors en significativité. Nous ne conserverons donc pas cette interactions.

    Nous allons donc rajouter ces interactions.

```{r}
mod_vide_poisson <- glm(Sinistres2 ~ 1, data = train, family = poisson(link="log"))
```

```{r}
mod_inter <- glm(Sinistres2 ~ ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+BonusMalus+DrivAge_fact+Categ+Risque*MariStat+HasKmLimit+VehUsage+Categ:MariStat+Categ:DrivAge_fact, data = train, family = poisson(link = "log"))
summary(mod_inter)
```

```{r}
mod_final <- step(mod_inter, mod_vide_poisson, trace = F, direction = c('both'))
summary(mod_final)
```

```{r}
BIC(mod_final)
BIC(mod_vide_poisson)
BIC(mod)
BIC(mod_inter)
```

## b) Suppression de valeurs extrêmes

Comme vu sur la fin de la partie Test avec une loi de Poisson, nous allons considérer dans un premier temps les observations qui possèdent un faible nombre de sinistres.

```{r}
quantile(freMPL5$Sinistres, c(0, 0.8, 0.9, seq(0.9,1,0.005)))
```

Ces quantiles pourront éventuellement nous aider à comprendre le pourcentage de variables que nous ignorons dans un premier temps.

#### \<= 3 (pas concluant)

```{r}
inf3 = freMPL5[freMPL5$Sinistres <= 3,]
nrow(freMPL5)-nrow(inf3)
(nrow(freMPL5)-nrow(inf3))/nrow(freMPL5)
```

On ne perd que 453 observations avec ce procédé, ce qui représente moins de 1,8% des assurés.

```{r}
lmb3 = mean(inf3$Sinistres2)
qqplot (inf3$Sinistres2, qpois(ppoints(inf3$Sinistres2), lambda = lmb3),
        	xlab ="Sinistralité observées",
        main ="Graphique des quantiles pour la sinistralité.")
abline (a=0,b=1, col ="red")
```

Ce graphe est déjà plus normal pour le qqplot. On peut aussi remarquer que :

$$
 \lambda_3 \approx 0,1187 << \lambda_{général} \approx 0,2667
$$

On capte dejà mieux les effets.

```{r}
echantillon3 <- sample(c(TRUE, FALSE), nrow(inf3), replace=TRUE, prob=c(0.8,0.2))
train3  <- inf3[echantillon, ]
test3   <- inf3[!echantillon, ]
```

```{r}
hist(inf3$Sinistres)
hist(inf3$Sinistres, ylim=c(0,1000))
```

Avec ces courbes, on remarque qu'on risque d'être en difficulté pour capter des valeurs précises entre 1 et 3 car le poids mis en 0 est très fort.

```{r}
mod0_3 <- glm(Sinistres2 ~ 1, data = train3, family = poisson(link = "log"))
summary(mod0_3)
```

```{r}
modFull_3 <- glm(Sinistres2 ~ MariStat+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact+Categ, data = train3, family = poisson(link = "log"))
summary(modFull_3)
```

```{r}
plot(modFull_3)
```

```{r}
modQuasiPoi_3 <- glm(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train3, family = quasipoisson(link = "log"))
summary(modQuasiPoi_3)
```

L'AIC n'est pas défini pour les quasi-Poisson sur R. Cependant, on remaque qu'on semble obtenir les mêmes résultats que pour la loi de Poisson normale. Y-a-t'il un problème dans le code ?

##### Prédiction

```{r}
estimation3 <- modFull_3$fitted.values
hist(estimation3)
```

##### RMSE

```{r}
RMSE_train <- sqrt(mean(modFull_3$residuals^2))
RMSE_train
```

##### Table de confusion

```{r}
estimation3 <- modFull_3$fitted.values
hist(estimation3)
score <- round(predict(modFull_3,train3,type="response"))
confusion.mat = table(train3$Sinistres2, score)  

confusion.mat
```

```{r}
estimation3 <- modFull_3$fitted.values
hist(estimation3)
score <- round(predict(modFull_3,test,type="response"))
confusion.mat = table(test3$Sinistres2, score)

confusion.mat
```

On obtient encore des résultats qui ne sont pas particulièrement satisfaisants.

#### \<= 4 (pas concluant)

```{r}
inf4 = freMPL5[freMPL5$Sinistres <= 4,]
nrow(inf4)
nrow(freMPL5)
```

```{r}
lmb4 = mean(inf4$Sinistres2)
qqplot (inf4$Sinistres2, qpois(ppoints(inf4$Sinistres2), lambda = lmb4),
        	xlab ="Sinistralité observées",
        main ="Graphique des quantiles pour la sinistralité.")
abline (a=0,b=1, col ="red")
```

Ce graphe semble moins bien que pour le découpage précédent (\<=3). On peut aussi remarquer que :

$$
 \lambda_4 \approx 0.1433 << \lambda_{général} \approx 0,2667
$$

```{r}
echantillon4 <- sample(c(TRUE, FALSE), nrow(inf4), replace=TRUE, prob=c(0.8,0.2))
train4  <- inf4[echantillon, ]
test4   <- inf4[!echantillon, ]
```

```{r}
hist(inf4$Sinistres)
hist(inf4$Sinistres, ylim=c(0,1000))
```

On peut dire à peu près les mêmes choses que pour la partie \<=3.

```{r}
mod0_4 <- glm(Sinistres2 ~ 1, data = train4, family = poisson(link = "log"))
summary(mod0_4)
```

```{r}
modFull_4 <- glm(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train4, family = poisson(link = "log"))
summary(modFull_4)
```

```{r}
modQuasiPoi_4 <- glm(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train4, family = quasipoisson(link = "log"))
summary(modQuasiPoi_4)
```

L'AIC n'est pas défini pour les quasi-Poisson sur R. Cependant, on remaque que les résidus sont plus importants sur la quasi-Poisson que sur la Poisson.

Nous perdons ici en précision et performance sur cette modélisation. Nous n'allons même pas tenter de regarder ce que cela donne sur l'échantillon de test.

```{r}
modNBFull_4 <- glm.nb(Sinistres2 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train4)
summary(modNBFull_4)
```

```{r}
modNB0_4 <- glm.nb(Sinistres2 ~ 1, data = train4)
summary(modNB0_4)
```

#### Seulement avec les sinistres \>1 (pas concluant)

##### Choix de partition

```{r}
cout = freMPL5[freMPL5$Sinistres>0,]
```

Nous allons créer un modèle de Poisson pour les variables qui ont au moins un Sinistre dans l'année pour ensuite faire une loi mélange (une loi bernouilli pour donner s'il y a au moins un sinistre ou pas, puis une loi de Poisson dans le cas où il y a au moins un sinistre pour determiner le nombre de sinistres). Tracons dans un premier temps les graphes quantiles-quantiles

```{r}
lmbSup1 = mean(cout$Sinistres2) -1
qqplot(cout$Sinistres2-1, qpois(ppoints(cout$Sinistres2), lambda = lmbSup1), xlab ="Sinistralité observées", main ="Graphique des quantiles pour la sinistralité.", xlim=c(0,50))
abline (a=0,b=1, col ="red")
```

Encore une fois, on a une surdispersion assez forte pour les grandes valeurs, ce qui peut être dû à quelques valeurs extrèmes.

Remarque pratique :

Par ailleurs, on pourra considérer que ces valeurs sont dû au fait qu'on divise parfois 1 (=ClaimInd) par un Exposure très petit. Dans la réalité, l'assuré n'a pas plus de 10 ou 20 sinistres par an.

```{r}
coutInf10 = cout[cout$Sinistres2<10,]
lmbSup1Inf10 = mean(coutInf10$Sinistres2) -1
qqplot(coutInf10$Sinistres2-1, qpois(ppoints(coutInf10$Sinistres2), lambda = lmbSup1Inf10), xlab ="Sinistralité observées", main ="Graphique des quantiles pour la sinistralité.")
abline (a=0,b=1, col ="red")
```

On remarque encore une fois qu'on s'éloigne légèrement d'une loi de Poisson dans les quantiles.

```{r}
coutInf7 = cout[cout$Sinistres2<7,]
lmbSup1Inf7 = mean(coutInf10$Sinistres2) -1
qqplot(coutInf7$Sinistres2 -1, qpois(ppoints(coutInf7$Sinistres2), lambda = lmbSup1Inf7), xlab ="Sinistralité observées", main ="Graphique des quantiles pour la sinistralité.")
abline (a=0,b=1, col ="red")
```

C'est peut-être avec ces caractéristiques que le graphe quantile-quantile est le mieux. Regardons ce qu'il en est de la modélisation.

##### Modélisation

```{r}
echantillonSup1Inf7 <- sample(c(TRUE, FALSE), nrow(coutInf7), replace=TRUE, prob=c(0.8,0.2))
train_1_7  <- coutInf7[echantillonSup1Inf7, ]
test_1_7   <- coutInf7[!echantillonSup1Inf7, ]
```

```{r}
mod_1_7 <- glm(Sinistres2 -1 ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+Risque+BonusMalus+DrivAge_fact, data = train_1_7, family = poisson(link = "log"))
summary(mod_1_7)
```

```{r}
mod_Vide<- glm(Sinistres2 -1 ~ 1, data = train_1_7, family = poisson(link = "log"))
summary(mod_Vide)
```

Il y a ici un vrai problème puisque le modèle vide a un meilleur critère AIC que le modèle complet... Essayons une méthode Both pour voir ce que ça donne mais ces premières informations nous font penser que cette modélisation ne pourra être gardée.

```{r}
modBoth_1_7 = step(mod_1_7, mod_Vide, trace=F, direction = c('both'))
summary(modBoth_1_7)
```

La méthode nous a enlevé presque toutes les variables. Donc nous n'allons clairement pas choisir cette modélisation.

## c) Etude des résidus

A partir des différentes modélisations ci-dessus et par une logique de sélection que nous expliciterons plus en profondeur dans le rendu écrit (LateX) du mémoire, nous allons conserver le modèle obtenu par un GLM de Poisson sur toutes les observations et les interactions. Nous allons donc effectuer une étude des résidus pour vérifier que nos données collent bien aux hypothèses du modèle.

```{r}
residus = resid(mod_final)
plot(mod_final)
```

### Visualisation des résidus

```{r}
plot(mod_final$fitted.values, residus, xlab = "Valeurs ajustées", ylab="Résidus", main = "Graphique en nuage de points des résidus par rapport aux valeurs ajustées")
plot(residus, type="h", ylab="Résidus standardisés", main = "Graphique en barres des résidus standardisés")
plot(resid(mod_final, type = "pearson"),type = "h", ylab="Résidus de Pearson", main="Graphique en barres des résidus de Pearson")
hist(residus, nclass=1000, xlim=c(-5,5))
```

Avec l'histogramme des résidus, on peut bien voir que le modèle a tendance à surévaluer le nombre de sinistres car les valeurs importantes de l'échantillon de données biaisent la prédiction.

## d) Etude des outliers

Calculons dans un premier temps les résidus de Pearson

```{r}
inf <- influence.measures(mod_final)
pearson_resid <- inf$infmat
```

```{r}
cooksd <- cooks.distance(modBoth_2)

sample_size <- nrow(train)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels
```

Voici un moyen classque de trouver et retirer les outliers.

```{r}
outliers=as.numeric(names(cooksd)[(cooksd > (4/length(train)))])

fin=length(outliers) #On pourrait ici modifier pour changer le nombre d'outliers à retirer du data d'entrainement.
(fin)
outliers=as.numeric(names(sort(cooksd, decreasing = TRUE)[1:fin]))

train_sansoutliers <- train[-c(outliers), ]

modFull_Outliers <- glm(Sinistres2 ~ ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+BonusMalus+DrivAge_fact+Categ+Risque*MariStat+HasKmLimit+VehUsage+Categ:MariStat+Categ:DrivAge_fact, data = train_sansoutliers, family = poisson(link = "log"))
summary(modFull_Outliers)
```

```{r}
summary(mod_inter)
```

On ne gagne pas beaucoup en AIC en retirant les outliers donc nous allons les garder.

```{r}
plot(modFull_Outliers)
```

## e) Qualité de prédiction

### Evaluation du modèle sur les données tests

```{r}
estimation <- mod_final$fitted.values
hist(estimation)
```

### Utilisation de métriques de comparaison

#### RMSE

```{r}
RMSE_train <- sqrt(mean(mod_final$residuals^2))
RMSE_train
```

### Table de confusion

#### Sur le jeu de données train

```{r}
estimation <- mod_final$fitted.values
hist(estimation)
score <- round(predict(mod_final,train,type="response"))
confusion.mat = table(train$Sinistres2, score)  

confusion.mat
```

#### Sur le jeu de données test

```{r}
estimation <- mod_final$fitted.values
hist(estimation)
score <- round(predict(mod_final,test,type="response"))
confusion.mat = table(test$Sinistres2, score)  

confusion.mat
```

# Conclusion

Le `mod_final` prédit plutôt bien les individus qui n'ont pas d'accidents (tout comme le modèle binomial) car ces individus représentent une grosse partie de l'échantillon. Cependant, pour les individus ayant eu des sinistres, l'estimation est plus difficile. Cependant, faute de pouvoir faire mieux avec les données dont nous disposons, c'est le modèle que nous garderons.

Pour rappel, voici le modèle :

```{r}
summary(mod_final)
```

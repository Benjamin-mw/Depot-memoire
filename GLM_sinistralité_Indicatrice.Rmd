---
title: "GLM_ClaimInd"
author: "Dudot Lucas - Lapaz Eudes - Moinard Benjamin - Nanoux Louis"
date: "2023-02-28"
output: html_document
---

Début habituel pour le code :

```{r}
#Packages
library(tables); library(ggExtra) ; library(FactoMineR) ; library(factoextra) ; library(CASdatasets)
library(tidyverse) ; library(MASS) ; library(knitr) ; library(ggplot2) ; library(cowplot)
library(reshape2) ; library(dplyr) ; library(GGally) ; library(corrplot) ; library(carData) 
library(car) ; library(questionr) ;library(multcomp) ; library(dplyr) ; library(leaps)
library(TeachingDemos) ; library(FactoMineR) ; library(factoextra) ; library(ROCR) ; library(plotROC)
library(graphics)

#Import jeu de données
data(freMPL5)
summary(freMPL5)

#Création d'une variable de sinistralité
freMPL5$Sinistres = freMPL5$ClaimInd/freMPL5$Exposure

#Ajustement type des variables
freMPL5$HasKmLimit <- factor(freMPL5$HasKmLimit)
freMPL5$RiskArea <- factor(freMPL5$RiskArea)
freMPL5$OutUseNb <- as.numeric(freMPL5$OutUseNb)

#Suppression des valeurs négatives
freMPL5 <- subset(freMPL5, freMPL5$ClaimAmount >= 0)

#Segmentation des tranches d'âge
freMPL5$DrivAge_fact <- cut(freMPL5$DrivAge, c(20,25,30,35,40,45,50,58,65,120), include.lowest = TRUE)

#Découpage CSP
freMPL5$Categ = 0
freMPL5$Categ[freMPL5$SocioCateg == "CSP50"] = 1
freMPL5$Categ[freMPL5$SocioCateg == "CSP55"] = 2
freMPL5$Categ[freMPL5$SocioCateg == "CSP60"] = 3
freMPL5$Categ[freMPL5$SocioCateg == "CSP1"] = 4
freMPL5$Categ[freMPL5$SocioCateg == "CSP42"] = 5
freMPL5$Categ[freMPL5$SocioCateg == "CSP46"] = 6
freMPL5$Categ[freMPL5$SocioCateg == "CSP48"] = 7
freMPL5$Categ[freMPL5$SocioCateg == "CSP66"] = 8
freMPL5$Categ = factor(freMPL5$Categ)
```

# Création d'un modèle linéaire généralisé

```{r}
set.seed(seed = 2023)
echantillon <- sample(c(TRUE, FALSE), nrow(freMPL5), replace=TRUE, prob=c(0.8,0.2))
train  <- freMPL5[echantillon, ]
test   <- freMPL5[!echantillon, ]
```

## Sélection de modèle

### Choix de modélisation

L'objectif de cette étude est d'expliquer "ClaimInd" (représenter par la variable $Y$) grâce à $p$variables explicatives que nous déterminerons.

Le code ci-dessous permet de savoir que l'évènement rare est "l'assuré a eu un sinistre" Par conséquent, on affecte la valeur 1 à cet évènement et 0 sinon (comme cela est déjà codé).

$Y$ est donc à valeurs dans $\text{{0;1}}$. La loi choisi pour cette modélisation est donc une loi de Bernouilli, avec comme fonction de lien canonique la fonction $logit$.

```{r}
Train_Contingence <- table(train$ClaimInd, train$ClaimInd)

x=c(Train_Contingence[1,1],Train_Contingence[2,2])
labels=c("Sans sinistre","Sinistre")
df=data.frame(x, labels)

ggplot(df, aes(x="", y=x, fill=labels)) +geom_bar(width = 1, stat ="identity") + coord_polar("y", start=0) +theme_void()+ggtitle("Sans/Avec sinistre")
```

La première étape dans la sélection de variables explicatives est l'étude des corrélations entre ses dernières.

Nous avons déjà fait cette étape dans la première partie donc nous allons donner directement le modèle.

Nous prendrons dans un premier temps toutes les variables sauf RecordBeg, RecordEnd, Gender (interdit par la législation française.

### Choix de selection de variables

Afin de sélectionner au mieux notre modèle, nous devons introduire un critère de sélection.

Le critère $AIC$ d'un modèle $[m]$ est

$$
AIC(m)=\frac{n}{2}\log(SCR(m))+m
$$

avec $SCR(m)=||P_mY-Y||^2$ et $n$ le nombre d'observations. On choisit un modèle $[m]$ qui minimise l'$AIC$. Afin de déterminer le "meilleur" modèle pour notre étude, nous utiliserons la méthode "both". Cette dernière part de l'intercept et ajoute/enlève les variables une à une tout en comparant selon le critère $AIC$

```{r, message = FALSE, warning = FALSE}
mod0 <- glm(ClaimInd ~ 1, data = train, offset = Exposure, family = binomial(link = logit))
summary(mod0)
```

```{r}
modFull <- glm(ClaimInd ~ MariStat+Categ+VehUsage+HasKmLimit+ClaimNbResp+ClaimNbNonResp+ClaimNbParking+ClaimNbFireTheft+ClaimNbWindscreen+OutUseNb+RiskArea+BonusMalus+DrivAge_fact, data = train, offset = Exposure, family = binomial(link = logit))
summary(modFull)
```

```{r}
modBoth = step(modFull, mod0, trace=F,direction = c('both'))
summary(modBoth)
```

Grâce à cette méthode nous obtenons un candidat pour notre modélisation.

## Etude de potentiels outliers

Un élément important à prendre en compte dans l'analyse des données est le traitement des outliers. Voyons si nous observons des candidats potentiels par lecture graphique

```{r}
plot(modBoth, 5)
```

Test pour voir si il y a des outliers :

```{r}
influenceIndexPlot(modBoth)

outlierTest(modBoth)
```

Si p-Bonferroni \>0,05, pas un outlier.

# Prédiction

## Evaluation du modèle sur les données tests

```{r}
estimation <- modBoth$fitted.values
hist(estimation)
```

## Utilisation de métriques de comparaison

### RMSE

#### Sur le jeu de données train

```{r}
RMSE_train <- sqrt(mean(modBoth$residuals^2))
RMSE_train
```

### AUC

#### Sur le jeu de données train

```{r}
pred=prediction(modBoth$fitted.values, train$ClaimInd)
perf=performance(pred,"tpr", "fpr")

auc_ROCR <- performance(pred, measure = "auc")
(auc_ROCR <- round(auc_ROCR@y.values[[1]],3) )
```

#### Sur le jeu de données test

```{r warning = FALSE}
prev_step <- predict(modBoth,newdata=test,type="response")
prev_prob <- data.frame(complet=predict(modFull,newdata=test, type="response"),step=predict(modBoth,newdata=test,type="response"))
head(round(prev_prob,3), n=3)
prev_class <- ifelse(prev_prob>0.2, 1, 0)
head(prev_class, n=3)
mean(as.factor(prev_class[,1])==test$ClaimInd)
mean(as.factor(prev_class[,2])==test$ClaimInd)


df_roc <- prev_prob %>% mutate(obs=as.numeric(test$ClaimInd)) %>% gather(key=methode,value=score,complet,step)
ggplot(df_roc, aes(m=score, d=obs,color=methode))+ geom_roc()
```

Les AUC obtenus sont supérieurs à 0,92. On a un très bon critère (très proche de 1).

### Table de confusion

#### Sur le jeu de données train

```{r}
estimation <- modBoth$fitted.values
hist(estimation)
score <- ifelse(predict(modBoth,train,type="response") >.2, 1, 0)
confusion.mat = table(train$ClaimInd, score)  
fauxneg = confusion.mat[2,1]
fauxpos = confusion.mat[1,2]
vraisneg = confusion.mat[1,1]
vraispos = confusion.mat[2,2]
(txerr = (fauxneg+fauxpos) / (fauxneg+fauxpos+vraisneg+vraispos))

sensibilite <- vraispos / (vraispos + fauxneg)   
precision <- vraispos / (vraispos + fauxpos) 
specificite <- vraisneg / (vraisneg + fauxpos)

confusion.mat
```

#### Sur le jeu de données test

```{r}
estimation <- modBoth$fitted.values
hist(estimation)
score <- ifelse(predict(modBoth,test,type="response") >.2, 1, 0)
confusion.mat = table(test$ClaimInd, score)  
fauxneg = confusion.mat[2,1]
fauxpos = confusion.mat[1,2]
vraisneg = confusion.mat[1,1]
vraispos = confusion.mat[2,2]
(txerr = (fauxneg+fauxpos) / (fauxneg+fauxpos+vraisneg+vraispos))
sensibilite <- vraispos / (vraispos + fauxneg)   
precision <- vraispos / (vraispos + fauxpos) 
specificite <- vraisneg / (vraisneg + fauxpos)

confusion.mat
```
